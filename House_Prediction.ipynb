{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datecru/House-Prices-Prediction-using-TF/blob/main/House_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H7baw9AxFuuI",
        "outputId": "18443903-7d98-4c87-bee9-853ce2cc996d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install tensorflow\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install seaborn\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "2d90-HDrIxEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "zqvzhh9kI42o",
        "outputId": "ad0d07ab-0d09-493c-ea02-ebd075c7031a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ff73083-8de7-47a3-a8f3-b3aa97367ce2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ff73083-8de7-47a3-a8f3-b3aa97367ce2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test.csv to test (1).csv\n",
            "Saving train.csv to train (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "df_train.head()\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "AC11jkwDJiNr",
        "outputId": "db5f3f61-9dc0-4660-a94a-04961275e39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
              "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
              "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
              "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
              "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
              "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
              "\n",
              "  LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence MiscFeature  \\\n",
              "0         Lvl    AllPub  ...         120        0    NaN  MnPrv         NaN   \n",
              "1         Lvl    AllPub  ...           0        0    NaN    NaN        Gar2   \n",
              "2         Lvl    AllPub  ...           0        0    NaN  MnPrv         NaN   \n",
              "3         Lvl    AllPub  ...           0        0    NaN    NaN         NaN   \n",
              "4         HLS    AllPub  ...         144        0    NaN    NaN         NaN   \n",
              "\n",
              "  MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
              "0       0      6    2010        WD         Normal  \n",
              "1   12500      6    2010        WD         Normal  \n",
              "2       0      3    2010        WD         Normal  \n",
              "3       0      6    2010        WD         Normal  \n",
              "4       0      1    2010        WD         Normal  \n",
              "\n",
              "[5 rows x 80 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e34b9f3-8ec7-4381-b1cf-cba0f0d98041\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>MSSubClass</th>\n",
              "      <th>MSZoning</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>Street</th>\n",
              "      <th>Alley</th>\n",
              "      <th>LotShape</th>\n",
              "      <th>LandContour</th>\n",
              "      <th>Utilities</th>\n",
              "      <th>...</th>\n",
              "      <th>ScreenPorch</th>\n",
              "      <th>PoolArea</th>\n",
              "      <th>PoolQC</th>\n",
              "      <th>Fence</th>\n",
              "      <th>MiscFeature</th>\n",
              "      <th>MiscVal</th>\n",
              "      <th>MoSold</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>SaleType</th>\n",
              "      <th>SaleCondition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>20</td>\n",
              "      <td>RH</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11622</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reg</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>20</td>\n",
              "      <td>RL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>14267</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Gar2</td>\n",
              "      <td>12500</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>74.0</td>\n",
              "      <td>13830</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MnPrv</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>60</td>\n",
              "      <td>RL</td>\n",
              "      <td>78.0</td>\n",
              "      <td>9978</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>Lvl</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>120</td>\n",
              "      <td>RL</td>\n",
              "      <td>43.0</td>\n",
              "      <td>5005</td>\n",
              "      <td>Pave</td>\n",
              "      <td>NaN</td>\n",
              "      <td>IR1</td>\n",
              "      <td>HLS</td>\n",
              "      <td>AllPub</td>\n",
              "      <td>...</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010</td>\n",
              "      <td>WD</td>\n",
              "      <td>Normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 80 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e34b9f3-8ec7-4381-b1cf-cba0f0d98041')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8e34b9f3-8ec7-4381-b1cf-cba0f0d98041 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8e34b9f3-8ec7-4381-b1cf-cba0f0d98041');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-088d9e33-2bb9-429a-91d2-1ef1bbdd51d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-088d9e33-2bb9-429a-91d2-1ef1bbdd51d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-088d9e33-2bb9-429a-91d2-1ef1bbdd51d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_numeric = df_train.select_dtypes(include=[np.number])\n",
        "df_train_numeric.head()\n",
        "\n",
        "df_test_numeric = df_test.select_dtypes(include=[np.number])\n",
        "df_test_numeric.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "collapsed": true,
        "id": "br5-kaQofXOK",
        "outputId": "9c2da499-2839-4b52-98c5-ef9997c45d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of         Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
              "0     1461          20         80.0    11622            5            6   \n",
              "1     1462          20         81.0    14267            6            6   \n",
              "2     1463          60         74.0    13830            5            5   \n",
              "3     1464          60         78.0     9978            6            6   \n",
              "4     1465         120         43.0     5005            8            5   \n",
              "...    ...         ...          ...      ...          ...          ...   \n",
              "1454  2915         160         21.0     1936            4            7   \n",
              "1455  2916         160         21.0     1894            4            5   \n",
              "1456  2917          20        160.0    20000            5            7   \n",
              "1457  2918          85         62.0    10441            5            5   \n",
              "1458  2919          60         74.0     9627            7            5   \n",
              "\n",
              "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  GarageArea  \\\n",
              "0          1961          1961         0.0       468.0  ...       730.0   \n",
              "1          1958          1958       108.0       923.0  ...       312.0   \n",
              "2          1997          1998         0.0       791.0  ...       482.0   \n",
              "3          1998          1998        20.0       602.0  ...       470.0   \n",
              "4          1992          1992         0.0       263.0  ...       506.0   \n",
              "...         ...           ...         ...         ...  ...         ...   \n",
              "1454       1970          1970         0.0         0.0  ...         0.0   \n",
              "1455       1970          1970         0.0       252.0  ...       286.0   \n",
              "1456       1960          1996         0.0      1224.0  ...       576.0   \n",
              "1457       1992          1992         0.0       337.0  ...         0.0   \n",
              "1458       1993          1994        94.0       758.0  ...       650.0   \n",
              "\n",
              "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
              "0            140            0              0          0          120   \n",
              "1            393           36              0          0            0   \n",
              "2            212           34              0          0            0   \n",
              "3            360           36              0          0            0   \n",
              "4              0           82              0          0          144   \n",
              "...          ...          ...            ...        ...          ...   \n",
              "1454           0            0              0          0            0   \n",
              "1455           0           24              0          0            0   \n",
              "1456         474            0              0          0            0   \n",
              "1457          80           32              0          0            0   \n",
              "1458         190           48              0          0            0   \n",
              "\n",
              "      PoolArea  MiscVal  MoSold  YrSold  \n",
              "0            0        0       6    2010  \n",
              "1            0    12500       6    2010  \n",
              "2            0        0       3    2010  \n",
              "3            0        0       6    2010  \n",
              "4            0        0       1    2010  \n",
              "...        ...      ...     ...     ...  \n",
              "1454         0        0       6    2006  \n",
              "1455         0        0       4    2006  \n",
              "1456         0        0       9    2006  \n",
              "1457         0      700       7    2006  \n",
              "1458         0        0      11    2006  \n",
              "\n",
              "[1459 rows x 37 columns]>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.generic.NDFrame.head</b><br/>def head(n: int=5) -&gt; NDFrameT</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py</a>Return the first `n` rows.\n",
              "\n",
              "This function returns the first `n` rows for the object based\n",
              "on position. It is useful for quickly testing if your object\n",
              "has the right type of data in it.\n",
              "\n",
              "For negative values of `n`, this function returns all rows except\n",
              "the last `|n|` rows, equivalent to ``df[:n]``.\n",
              "\n",
              "If n is larger than the number of rows, this function returns all rows.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "n : int, default 5\n",
              "    Number of rows to select.\n",
              "\n",
              "Returns\n",
              "-------\n",
              "same type as caller\n",
              "    The first `n` rows of the caller object.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.tail: Returns the last `n` rows.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; df = pd.DataFrame({&#x27;animal&#x27;: [&#x27;alligator&#x27;, &#x27;bee&#x27;, &#x27;falcon&#x27;, &#x27;lion&#x27;,\n",
              "...                    &#x27;monkey&#x27;, &#x27;parrot&#x27;, &#x27;shark&#x27;, &#x27;whale&#x27;, &#x27;zebra&#x27;]})\n",
              "&gt;&gt;&gt; df\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "5     parrot\n",
              "6      shark\n",
              "7      whale\n",
              "8      zebra\n",
              "\n",
              "Viewing the first 5 lines\n",
              "\n",
              "&gt;&gt;&gt; df.head()\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "\n",
              "Viewing the first `n` lines (three in this case)\n",
              "\n",
              "&gt;&gt;&gt; df.head(3)\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "\n",
              "For negative values of `n`\n",
              "\n",
              "&gt;&gt;&gt; df.head(-3)\n",
              "      animal\n",
              "0  alligator\n",
              "1        bee\n",
              "2     falcon\n",
              "3       lion\n",
              "4     monkey\n",
              "5     parrot</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5559);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_numeric = df_train_numeric.fillna(df_train_numeric.mean())\n",
        "df_test_numeric = df_test_numeric.fillna(df_test_numeric.mean())"
      ],
      "metadata": {
        "id": "EsS5uPoQgtJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'SalePrice' in df_train_numeric.columns:\n",
        "    x_train = df_train_numeric.drop('SalePrice', axis=1).values\n",
        "    y_train = df_train_numeric['SalePrice'].values\n",
        "\n",
        "else:\n",
        "    x_train = df_train_numeric.values\n",
        "\n",
        "x_test = df_test_numeric.values"
      ],
      "metadata": {
        "id": "vLFl2Dxfg5ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalize Data"
      ],
      "metadata": {
        "id": "aasLRtLSiSdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "\n",
        "x_test_scaled = scaler.transform(x_test)\n"
      ],
      "metadata": {
        "id": "LW75Kr25ho07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Model"
      ],
      "metadata": {
        "id": "RGJHfHK0iYEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_dim):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(128, activation='relu', input_dim=input_dim, kernel_regularizer=l2(0.01)))\n",
        "  model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "  model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "  model.add(Dense(1, activation='linear'))\n",
        "\n",
        "  optimizer = Adam(learning_rate=0.001)\n",
        "  model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "  return model\n",
        "\n",
        "model = create_model(x_train_scaled.shape[1])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_rreYGPiWQ9",
        "outputId": "9054a9b2-ccf4-4131-b9c1-6e3505c1ccbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 128)               4864      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17345 (67.75 KB)\n",
            "Trainable params: 17345 (67.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train_scaled, y_train, epochs=1000, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuNbYS_T--gX",
        "outputId": "2b4972e1-f8cc-4f1e-f740-83819f63a41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 682672640.0000 - val_loss: 2153801472.0000\n",
            "Epoch 2/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 681332032.0000 - val_loss: 2186402816.0000\n",
            "Epoch 3/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 681105600.0000 - val_loss: 2171532544.0000\n",
            "Epoch 4/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 678775936.0000 - val_loss: 2168969216.0000\n",
            "Epoch 5/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 688946112.0000 - val_loss: 2163174400.0000\n",
            "Epoch 6/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 674012864.0000 - val_loss: 2140413184.0000\n",
            "Epoch 7/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 669216832.0000 - val_loss: 2166130432.0000\n",
            "Epoch 8/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 669475072.0000 - val_loss: 2132543488.0000\n",
            "Epoch 9/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 666221120.0000 - val_loss: 2141819776.0000\n",
            "Epoch 10/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 664518848.0000 - val_loss: 2139392896.0000\n",
            "Epoch 11/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 663601408.0000 - val_loss: 2167969024.0000\n",
            "Epoch 12/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 660680064.0000 - val_loss: 2136365440.0000\n",
            "Epoch 13/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 656564480.0000 - val_loss: 2147917824.0000\n",
            "Epoch 14/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 656781184.0000 - val_loss: 2134420224.0000\n",
            "Epoch 15/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 655827776.0000 - val_loss: 2132768512.0000\n",
            "Epoch 16/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 651291840.0000 - val_loss: 2138208000.0000\n",
            "Epoch 17/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 648322112.0000 - val_loss: 2134060416.0000\n",
            "Epoch 18/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 650221056.0000 - val_loss: 2123021440.0000\n",
            "Epoch 19/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 653163392.0000 - val_loss: 2123385216.0000\n",
            "Epoch 20/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 643354112.0000 - val_loss: 2145592704.0000\n",
            "Epoch 21/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 642867264.0000 - val_loss: 2127911040.0000\n",
            "Epoch 22/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 639299776.0000 - val_loss: 2140251392.0000\n",
            "Epoch 23/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 643274368.0000 - val_loss: 2126291712.0000\n",
            "Epoch 24/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 637679936.0000 - val_loss: 2126697344.0000\n",
            "Epoch 25/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 636682560.0000 - val_loss: 2126435584.0000\n",
            "Epoch 26/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 635552640.0000 - val_loss: 2128104320.0000\n",
            "Epoch 27/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 634045056.0000 - val_loss: 2139037824.0000\n",
            "Epoch 28/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 649772608.0000 - val_loss: 2149141248.0000\n",
            "Epoch 29/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 638623104.0000 - val_loss: 2137627008.0000\n",
            "Epoch 30/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 630758080.0000 - val_loss: 2136558208.0000\n",
            "Epoch 31/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 633703424.0000 - val_loss: 2120356480.0000\n",
            "Epoch 32/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 629021440.0000 - val_loss: 2122003840.0000\n",
            "Epoch 33/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 624041216.0000 - val_loss: 2121277568.0000\n",
            "Epoch 34/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 628186432.0000 - val_loss: 2125789440.0000\n",
            "Epoch 35/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 625358656.0000 - val_loss: 2145245056.0000\n",
            "Epoch 36/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 623957056.0000 - val_loss: 2106763776.0000\n",
            "Epoch 37/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 625417216.0000 - val_loss: 2133140224.0000\n",
            "Epoch 38/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 630931776.0000 - val_loss: 2136710400.0000\n",
            "Epoch 39/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 615798976.0000 - val_loss: 2122949632.0000\n",
            "Epoch 40/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 615623680.0000 - val_loss: 2135265920.0000\n",
            "Epoch 41/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 617891072.0000 - val_loss: 2137371392.0000\n",
            "Epoch 42/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 619347584.0000 - val_loss: 2146429056.0000\n",
            "Epoch 43/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 619929536.0000 - val_loss: 2144234240.0000\n",
            "Epoch 44/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 609585600.0000 - val_loss: 2111647360.0000\n",
            "Epoch 45/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 612870784.0000 - val_loss: 2111110016.0000\n",
            "Epoch 46/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 613544064.0000 - val_loss: 2132614144.0000\n",
            "Epoch 47/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 615144128.0000 - val_loss: 2146023424.0000\n",
            "Epoch 48/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 618674688.0000 - val_loss: 2129289984.0000\n",
            "Epoch 49/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 606353856.0000 - val_loss: 2134590080.0000\n",
            "Epoch 50/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 607108928.0000 - val_loss: 2120262656.0000\n",
            "Epoch 51/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 610047680.0000 - val_loss: 2128747520.0000\n",
            "Epoch 52/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 619282688.0000 - val_loss: 2160934656.0000\n",
            "Epoch 53/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 602477248.0000 - val_loss: 2111129088.0000\n",
            "Epoch 54/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 601131392.0000 - val_loss: 2126210432.0000\n",
            "Epoch 55/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 599523776.0000 - val_loss: 2139385728.0000\n",
            "Epoch 56/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 599291904.0000 - val_loss: 2132232832.0000\n",
            "Epoch 57/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 599834304.0000 - val_loss: 2128786304.0000\n",
            "Epoch 58/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 598788608.0000 - val_loss: 2141688704.0000\n",
            "Epoch 59/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 595331072.0000 - val_loss: 2124927616.0000\n",
            "Epoch 60/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 596298112.0000 - val_loss: 2140807040.0000\n",
            "Epoch 61/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 595928448.0000 - val_loss: 2114039424.0000\n",
            "Epoch 62/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 595343808.0000 - val_loss: 2125036672.0000\n",
            "Epoch 63/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 602261696.0000 - val_loss: 2141417728.0000\n",
            "Epoch 64/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 590356096.0000 - val_loss: 2129325696.0000\n",
            "Epoch 65/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 587060160.0000 - val_loss: 2116023680.0000\n",
            "Epoch 66/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 590293824.0000 - val_loss: 2129441024.0000\n",
            "Epoch 67/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 587361792.0000 - val_loss: 2112342912.0000\n",
            "Epoch 68/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 592418816.0000 - val_loss: 2153839616.0000\n",
            "Epoch 69/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 585329536.0000 - val_loss: 2129742208.0000\n",
            "Epoch 70/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 602921920.0000 - val_loss: 2121948800.0000\n",
            "Epoch 71/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 583822464.0000 - val_loss: 2098825472.0000\n",
            "Epoch 72/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 588150976.0000 - val_loss: 2126892800.0000\n",
            "Epoch 73/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 582876672.0000 - val_loss: 2097079040.0000\n",
            "Epoch 74/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 582978368.0000 - val_loss: 2110818560.0000\n",
            "Epoch 75/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 578660416.0000 - val_loss: 2112710528.0000\n",
            "Epoch 76/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 580904768.0000 - val_loss: 2142222592.0000\n",
            "Epoch 77/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 580344256.0000 - val_loss: 2116693376.0000\n",
            "Epoch 78/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 582283072.0000 - val_loss: 2098160384.0000\n",
            "Epoch 79/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 585804416.0000 - val_loss: 2096979200.0000\n",
            "Epoch 80/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 573811456.0000 - val_loss: 2136714624.0000\n",
            "Epoch 81/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 578679936.0000 - val_loss: 2119837568.0000\n",
            "Epoch 82/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 575740672.0000 - val_loss: 2136466816.0000\n",
            "Epoch 83/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 574109696.0000 - val_loss: 2120819200.0000\n",
            "Epoch 84/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 574967744.0000 - val_loss: 2126291456.0000\n",
            "Epoch 85/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 569972928.0000 - val_loss: 2125273472.0000\n",
            "Epoch 86/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 568210240.0000 - val_loss: 2113611648.0000\n",
            "Epoch 87/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 569838656.0000 - val_loss: 2147278336.0000\n",
            "Epoch 88/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 570828672.0000 - val_loss: 2125434624.0000\n",
            "Epoch 89/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 566676992.0000 - val_loss: 2153868800.0000\n",
            "Epoch 90/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 567997376.0000 - val_loss: 2126648832.0000\n",
            "Epoch 91/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 563514048.0000 - val_loss: 2126193024.0000\n",
            "Epoch 92/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 564308416.0000 - val_loss: 2111246720.0000\n",
            "Epoch 93/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 567200320.0000 - val_loss: 2126099584.0000\n",
            "Epoch 94/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 564012992.0000 - val_loss: 2109323776.0000\n",
            "Epoch 95/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 565250560.0000 - val_loss: 2156697856.0000\n",
            "Epoch 96/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 566871104.0000 - val_loss: 2107726208.0000\n",
            "Epoch 97/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 565708160.0000 - val_loss: 2119637632.0000\n",
            "Epoch 98/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 565549248.0000 - val_loss: 2144612224.0000\n",
            "Epoch 99/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 561570944.0000 - val_loss: 2105409024.0000\n",
            "Epoch 100/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 557014656.0000 - val_loss: 2162380288.0000\n",
            "Epoch 101/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 560242816.0000 - val_loss: 2116233728.0000\n",
            "Epoch 102/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 558705728.0000 - val_loss: 2184365312.0000\n",
            "Epoch 103/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 557946432.0000 - val_loss: 2122699648.0000\n",
            "Epoch 104/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 552308544.0000 - val_loss: 2146409472.0000\n",
            "Epoch 105/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 560075712.0000 - val_loss: 2114616448.0000\n",
            "Epoch 106/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 560134528.0000 - val_loss: 2104938880.0000\n",
            "Epoch 107/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 564334336.0000 - val_loss: 2110349696.0000\n",
            "Epoch 108/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 552400512.0000 - val_loss: 2140657536.0000\n",
            "Epoch 109/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 552687040.0000 - val_loss: 2116304384.0000\n",
            "Epoch 110/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 552242944.0000 - val_loss: 2117986176.0000\n",
            "Epoch 111/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 552695744.0000 - val_loss: 2131958528.0000\n",
            "Epoch 112/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 549123072.0000 - val_loss: 2145666176.0000\n",
            "Epoch 113/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 545071296.0000 - val_loss: 2123952896.0000\n",
            "Epoch 114/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 546128576.0000 - val_loss: 2141431936.0000\n",
            "Epoch 115/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 545749760.0000 - val_loss: 2122660992.0000\n",
            "Epoch 116/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 549470336.0000 - val_loss: 2140243968.0000\n",
            "Epoch 117/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 541895040.0000 - val_loss: 2137784320.0000\n",
            "Epoch 118/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 554445696.0000 - val_loss: 2107786624.0000\n",
            "Epoch 119/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 545390464.0000 - val_loss: 2127143424.0000\n",
            "Epoch 120/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 541355776.0000 - val_loss: 2128466304.0000\n",
            "Epoch 121/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 541744896.0000 - val_loss: 2129742720.0000\n",
            "Epoch 122/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 539130816.0000 - val_loss: 2133700864.0000\n",
            "Epoch 123/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 543294592.0000 - val_loss: 2137654656.0000\n",
            "Epoch 124/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 537165696.0000 - val_loss: 2132509824.0000\n",
            "Epoch 125/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 538856128.0000 - val_loss: 2133304064.0000\n",
            "Epoch 126/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 539354624.0000 - val_loss: 2141296128.0000\n",
            "Epoch 127/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 538978368.0000 - val_loss: 2162877184.0000\n",
            "Epoch 128/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 535373792.0000 - val_loss: 2141209216.0000\n",
            "Epoch 129/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 537744192.0000 - val_loss: 2139892224.0000\n",
            "Epoch 130/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 542342336.0000 - val_loss: 2122938368.0000\n",
            "Epoch 131/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 534766976.0000 - val_loss: 2175408128.0000\n",
            "Epoch 132/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 542236736.0000 - val_loss: 2130351360.0000\n",
            "Epoch 133/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 529712384.0000 - val_loss: 2153219328.0000\n",
            "Epoch 134/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 534308320.0000 - val_loss: 2169385728.0000\n",
            "Epoch 135/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 531794336.0000 - val_loss: 2128317952.0000\n",
            "Epoch 136/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 536195232.0000 - val_loss: 2126760192.0000\n",
            "Epoch 137/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 527578208.0000 - val_loss: 2162762496.0000\n",
            "Epoch 138/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 529618176.0000 - val_loss: 2152929024.0000\n",
            "Epoch 139/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 528548448.0000 - val_loss: 2126422528.0000\n",
            "Epoch 140/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 534044160.0000 - val_loss: 2128450176.0000\n",
            "Epoch 141/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 528113376.0000 - val_loss: 2157625088.0000\n",
            "Epoch 142/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 528481408.0000 - val_loss: 2139978240.0000\n",
            "Epoch 143/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 528443072.0000 - val_loss: 2141783424.0000\n",
            "Epoch 144/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 525950912.0000 - val_loss: 2125838848.0000\n",
            "Epoch 145/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 524250624.0000 - val_loss: 2159606528.0000\n",
            "Epoch 146/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 524821536.0000 - val_loss: 2127432832.0000\n",
            "Epoch 147/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 531244576.0000 - val_loss: 2156875008.0000\n",
            "Epoch 148/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 523041920.0000 - val_loss: 2137166848.0000\n",
            "Epoch 149/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 521193728.0000 - val_loss: 2183816960.0000\n",
            "Epoch 150/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 530208864.0000 - val_loss: 2159759872.0000\n",
            "Epoch 151/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 522810528.0000 - val_loss: 2142917248.0000\n",
            "Epoch 152/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 517744736.0000 - val_loss: 2136160768.0000\n",
            "Epoch 153/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 520424576.0000 - val_loss: 2160843520.0000\n",
            "Epoch 154/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 518554784.0000 - val_loss: 2130422528.0000\n",
            "Epoch 155/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 523231616.0000 - val_loss: 2136554112.0000\n",
            "Epoch 156/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 522909952.0000 - val_loss: 2200050688.0000\n",
            "Epoch 157/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 519836672.0000 - val_loss: 2114822656.0000\n",
            "Epoch 158/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 529044352.0000 - val_loss: 2127838080.0000\n",
            "Epoch 159/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 518722720.0000 - val_loss: 2189837312.0000\n",
            "Epoch 160/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 516365952.0000 - val_loss: 2142060032.0000\n",
            "Epoch 161/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 511929632.0000 - val_loss: 2149425152.0000\n",
            "Epoch 162/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 515749760.0000 - val_loss: 2160887552.0000\n",
            "Epoch 163/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 514798400.0000 - val_loss: 2184824064.0000\n",
            "Epoch 164/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 517031360.0000 - val_loss: 2117322496.0000\n",
            "Epoch 165/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 514553280.0000 - val_loss: 2148378880.0000\n",
            "Epoch 166/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 513825984.0000 - val_loss: 2176806144.0000\n",
            "Epoch 167/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 511832416.0000 - val_loss: 2119035008.0000\n",
            "Epoch 168/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 512674784.0000 - val_loss: 2192010496.0000\n",
            "Epoch 169/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 515586752.0000 - val_loss: 2159024384.0000\n",
            "Epoch 170/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 512056992.0000 - val_loss: 2133283840.0000\n",
            "Epoch 171/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 507839040.0000 - val_loss: 2150568448.0000\n",
            "Epoch 172/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 507051648.0000 - val_loss: 2144945664.0000\n",
            "Epoch 173/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 510132832.0000 - val_loss: 2138233600.0000\n",
            "Epoch 174/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 507543328.0000 - val_loss: 2164574976.0000\n",
            "Epoch 175/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 509103968.0000 - val_loss: 2128241664.0000\n",
            "Epoch 176/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 502398176.0000 - val_loss: 2171611392.0000\n",
            "Epoch 177/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 503268800.0000 - val_loss: 2174669312.0000\n",
            "Epoch 178/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 506307136.0000 - val_loss: 2157687296.0000\n",
            "Epoch 179/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 504534464.0000 - val_loss: 2153258752.0000\n",
            "Epoch 180/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 506747360.0000 - val_loss: 2156246016.0000\n",
            "Epoch 181/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 506611840.0000 - val_loss: 2120575744.0000\n",
            "Epoch 182/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 510967648.0000 - val_loss: 2152019200.0000\n",
            "Epoch 183/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 500843392.0000 - val_loss: 2168876800.0000\n",
            "Epoch 184/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 501331424.0000 - val_loss: 2146720768.0000\n",
            "Epoch 185/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 497724096.0000 - val_loss: 2159409664.0000\n",
            "Epoch 186/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 505323296.0000 - val_loss: 2100563712.0000\n",
            "Epoch 187/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 512836928.0000 - val_loss: 2145718400.0000\n",
            "Epoch 188/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 496302784.0000 - val_loss: 2181194496.0000\n",
            "Epoch 189/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 507455072.0000 - val_loss: 2142959616.0000\n",
            "Epoch 190/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 496090304.0000 - val_loss: 2174574336.0000\n",
            "Epoch 191/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 496017696.0000 - val_loss: 2138261248.0000\n",
            "Epoch 192/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 501066816.0000 - val_loss: 2169003008.0000\n",
            "Epoch 193/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 492388000.0000 - val_loss: 2146732928.0000\n",
            "Epoch 194/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 498933184.0000 - val_loss: 2175853056.0000\n",
            "Epoch 195/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 494949984.0000 - val_loss: 2214110464.0000\n",
            "Epoch 196/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 500555840.0000 - val_loss: 2206821632.0000\n",
            "Epoch 197/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 491954176.0000 - val_loss: 2159225088.0000\n",
            "Epoch 198/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 490081792.0000 - val_loss: 2183729664.0000\n",
            "Epoch 199/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 490105184.0000 - val_loss: 2141428096.0000\n",
            "Epoch 200/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 488119264.0000 - val_loss: 2158868224.0000\n",
            "Epoch 201/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 491512544.0000 - val_loss: 2149562624.0000\n",
            "Epoch 202/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 486352128.0000 - val_loss: 2161501952.0000\n",
            "Epoch 203/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 486727456.0000 - val_loss: 2168870656.0000\n",
            "Epoch 204/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 497916448.0000 - val_loss: 2141533056.0000\n",
            "Epoch 205/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 482032640.0000 - val_loss: 2188904704.0000\n",
            "Epoch 206/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 503347456.0000 - val_loss: 2151795456.0000\n",
            "Epoch 207/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 486344384.0000 - val_loss: 2153914368.0000\n",
            "Epoch 208/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 486811328.0000 - val_loss: 2173469696.0000\n",
            "Epoch 209/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 486333184.0000 - val_loss: 2148567808.0000\n",
            "Epoch 210/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 486515520.0000 - val_loss: 2148985856.0000\n",
            "Epoch 211/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 489989600.0000 - val_loss: 2182096384.0000\n",
            "Epoch 212/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 482254496.0000 - val_loss: 2188653568.0000\n",
            "Epoch 213/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 485495136.0000 - val_loss: 2150366208.0000\n",
            "Epoch 214/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 489016288.0000 - val_loss: 2134706560.0000\n",
            "Epoch 215/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 486471328.0000 - val_loss: 2198042368.0000\n",
            "Epoch 216/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 492418208.0000 - val_loss: 2183735040.0000\n",
            "Epoch 217/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 482258272.0000 - val_loss: 2186892032.0000\n",
            "Epoch 218/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 476569536.0000 - val_loss: 2173433344.0000\n",
            "Epoch 219/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 478437728.0000 - val_loss: 2149807360.0000\n",
            "Epoch 220/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 477857760.0000 - val_loss: 2200196608.0000\n",
            "Epoch 221/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 483076864.0000 - val_loss: 2124113280.0000\n",
            "Epoch 222/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 475469280.0000 - val_loss: 2199906304.0000\n",
            "Epoch 223/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 484258304.0000 - val_loss: 2158410496.0000\n",
            "Epoch 224/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 480204672.0000 - val_loss: 2143093376.0000\n",
            "Epoch 225/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 476860640.0000 - val_loss: 2150611712.0000\n",
            "Epoch 226/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 475114176.0000 - val_loss: 2190153984.0000\n",
            "Epoch 227/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 475763488.0000 - val_loss: 2186122240.0000\n",
            "Epoch 228/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 477171424.0000 - val_loss: 2150763776.0000\n",
            "Epoch 229/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 472398304.0000 - val_loss: 2212958976.0000\n",
            "Epoch 230/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 472229856.0000 - val_loss: 2180827136.0000\n",
            "Epoch 231/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 471307136.0000 - val_loss: 2149852160.0000\n",
            "Epoch 232/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 469774944.0000 - val_loss: 2184947712.0000\n",
            "Epoch 233/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 473915456.0000 - val_loss: 2216053248.0000\n",
            "Epoch 234/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 479024384.0000 - val_loss: 2141236352.0000\n",
            "Epoch 235/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 471970592.0000 - val_loss: 2182380800.0000\n",
            "Epoch 236/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 472970848.0000 - val_loss: 2246692096.0000\n",
            "Epoch 237/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 468598560.0000 - val_loss: 2165259520.0000\n",
            "Epoch 238/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 467745088.0000 - val_loss: 2179024384.0000\n",
            "Epoch 239/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 467471904.0000 - val_loss: 2157057536.0000\n",
            "Epoch 240/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 472953440.0000 - val_loss: 2181458944.0000\n",
            "Epoch 241/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 466433696.0000 - val_loss: 2178393600.0000\n",
            "Epoch 242/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 469609248.0000 - val_loss: 2219970048.0000\n",
            "Epoch 243/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 471464640.0000 - val_loss: 2154531584.0000\n",
            "Epoch 244/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 469516256.0000 - val_loss: 2227579136.0000\n",
            "Epoch 245/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 459183712.0000 - val_loss: 2159005440.0000\n",
            "Epoch 246/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 464048192.0000 - val_loss: 2182781184.0000\n",
            "Epoch 247/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 460827968.0000 - val_loss: 2182059520.0000\n",
            "Epoch 248/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 459778400.0000 - val_loss: 2179542272.0000\n",
            "Epoch 249/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 462468768.0000 - val_loss: 2153989376.0000\n",
            "Epoch 250/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 462771648.0000 - val_loss: 2147466624.0000\n",
            "Epoch 251/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 457291456.0000 - val_loss: 2206471168.0000\n",
            "Epoch 252/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 463994528.0000 - val_loss: 2200659712.0000\n",
            "Epoch 253/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 461061888.0000 - val_loss: 2204513536.0000\n",
            "Epoch 254/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 464975264.0000 - val_loss: 2243312896.0000\n",
            "Epoch 255/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 466169920.0000 - val_loss: 2153988864.0000\n",
            "Epoch 256/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 452753696.0000 - val_loss: 2211992320.0000\n",
            "Epoch 257/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 453861376.0000 - val_loss: 2180107008.0000\n",
            "Epoch 258/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 452685408.0000 - val_loss: 2177018880.0000\n",
            "Epoch 259/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 459964384.0000 - val_loss: 2242885120.0000\n",
            "Epoch 260/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 450264096.0000 - val_loss: 2163682816.0000\n",
            "Epoch 261/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 459623552.0000 - val_loss: 2167621632.0000\n",
            "Epoch 262/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 453112576.0000 - val_loss: 2233074688.0000\n",
            "Epoch 263/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 456942592.0000 - val_loss: 2198657280.0000\n",
            "Epoch 264/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 452086784.0000 - val_loss: 2182068480.0000\n",
            "Epoch 265/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 461344896.0000 - val_loss: 2180739072.0000\n",
            "Epoch 266/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 452656512.0000 - val_loss: 2132073088.0000\n",
            "Epoch 267/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 456105408.0000 - val_loss: 2163203584.0000\n",
            "Epoch 268/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 454247488.0000 - val_loss: 2169754624.0000\n",
            "Epoch 269/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 448513312.0000 - val_loss: 2195515648.0000\n",
            "Epoch 270/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 449824000.0000 - val_loss: 2155643904.0000\n",
            "Epoch 271/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 447636608.0000 - val_loss: 2205222144.0000\n",
            "Epoch 272/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 448040416.0000 - val_loss: 2211640064.0000\n",
            "Epoch 273/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 449804576.0000 - val_loss: 2166215424.0000\n",
            "Epoch 274/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 446376544.0000 - val_loss: 2190713088.0000\n",
            "Epoch 275/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 444866688.0000 - val_loss: 2179529984.0000\n",
            "Epoch 276/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 445443616.0000 - val_loss: 2169374976.0000\n",
            "Epoch 277/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 441638560.0000 - val_loss: 2202915584.0000\n",
            "Epoch 278/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 444310592.0000 - val_loss: 2180755968.0000\n",
            "Epoch 279/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 444858496.0000 - val_loss: 2180710144.0000\n",
            "Epoch 280/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 442113888.0000 - val_loss: 2253568256.0000\n",
            "Epoch 281/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 447154496.0000 - val_loss: 2194670080.0000\n",
            "Epoch 282/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 444595072.0000 - val_loss: 2253093888.0000\n",
            "Epoch 283/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 446599552.0000 - val_loss: 2154073600.0000\n",
            "Epoch 284/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 439643648.0000 - val_loss: 2216701440.0000\n",
            "Epoch 285/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 445863744.0000 - val_loss: 2241573120.0000\n",
            "Epoch 286/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 442388960.0000 - val_loss: 2194403072.0000\n",
            "Epoch 287/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 443009920.0000 - val_loss: 2236015616.0000\n",
            "Epoch 288/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 440206560.0000 - val_loss: 2179519232.0000\n",
            "Epoch 289/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 439244352.0000 - val_loss: 2225521664.0000\n",
            "Epoch 290/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 446465952.0000 - val_loss: 2191105024.0000\n",
            "Epoch 291/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 437040352.0000 - val_loss: 2183874816.0000\n",
            "Epoch 292/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 439228768.0000 - val_loss: 2212369920.0000\n",
            "Epoch 293/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 441449920.0000 - val_loss: 2190731264.0000\n",
            "Epoch 294/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 439451776.0000 - val_loss: 2243014656.0000\n",
            "Epoch 295/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 441097952.0000 - val_loss: 2237062912.0000\n",
            "Epoch 296/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 440670336.0000 - val_loss: 2175591168.0000\n",
            "Epoch 297/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 435291424.0000 - val_loss: 2176882688.0000\n",
            "Epoch 298/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 434726016.0000 - val_loss: 2215035904.0000\n",
            "Epoch 299/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 435375776.0000 - val_loss: 2244262144.0000\n",
            "Epoch 300/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 430611968.0000 - val_loss: 2192475136.0000\n",
            "Epoch 301/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 432871872.0000 - val_loss: 2174778624.0000\n",
            "Epoch 302/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 430235104.0000 - val_loss: 2227521024.0000\n",
            "Epoch 303/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 435651360.0000 - val_loss: 2289021696.0000\n",
            "Epoch 304/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 434012128.0000 - val_loss: 2203592448.0000\n",
            "Epoch 305/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 436433472.0000 - val_loss: 2320430336.0000\n",
            "Epoch 306/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 430383552.0000 - val_loss: 2206947840.0000\n",
            "Epoch 307/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 428366336.0000 - val_loss: 2197530624.0000\n",
            "Epoch 308/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 427084800.0000 - val_loss: 2212025088.0000\n",
            "Epoch 309/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 426115168.0000 - val_loss: 2177018112.0000\n",
            "Epoch 310/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 429442944.0000 - val_loss: 2243889408.0000\n",
            "Epoch 311/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 433505600.0000 - val_loss: 2222681344.0000\n",
            "Epoch 312/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 425376224.0000 - val_loss: 2222804992.0000\n",
            "Epoch 313/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 427680032.0000 - val_loss: 2205157376.0000\n",
            "Epoch 314/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 424025440.0000 - val_loss: 2192460544.0000\n",
            "Epoch 315/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 422844192.0000 - val_loss: 2197938432.0000\n",
            "Epoch 316/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 421917344.0000 - val_loss: 2213408512.0000\n",
            "Epoch 317/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 425214208.0000 - val_loss: 2224764160.0000\n",
            "Epoch 318/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 422359936.0000 - val_loss: 2181191168.0000\n",
            "Epoch 319/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 427563328.0000 - val_loss: 2235725312.0000\n",
            "Epoch 320/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 423571296.0000 - val_loss: 2272382464.0000\n",
            "Epoch 321/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 418401312.0000 - val_loss: 2193563392.0000\n",
            "Epoch 322/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 425433920.0000 - val_loss: 2302382336.0000\n",
            "Epoch 323/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 427418144.0000 - val_loss: 2166930944.0000\n",
            "Epoch 324/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 418278944.0000 - val_loss: 2257931264.0000\n",
            "Epoch 325/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 426350912.0000 - val_loss: 2245841408.0000\n",
            "Epoch 326/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 418469632.0000 - val_loss: 2217760256.0000\n",
            "Epoch 327/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 415274464.0000 - val_loss: 2179350528.0000\n",
            "Epoch 328/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 419122016.0000 - val_loss: 2200364800.0000\n",
            "Epoch 329/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 418525568.0000 - val_loss: 2282223872.0000\n",
            "Epoch 330/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 422098560.0000 - val_loss: 2236711936.0000\n",
            "Epoch 331/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 417544384.0000 - val_loss: 2195618816.0000\n",
            "Epoch 332/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 414752224.0000 - val_loss: 2205622272.0000\n",
            "Epoch 333/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 416699232.0000 - val_loss: 2205782784.0000\n",
            "Epoch 334/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 411569376.0000 - val_loss: 2246843648.0000\n",
            "Epoch 335/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 416143712.0000 - val_loss: 2244274944.0000\n",
            "Epoch 336/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 412743840.0000 - val_loss: 2221190656.0000\n",
            "Epoch 337/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 414370112.0000 - val_loss: 2205729024.0000\n",
            "Epoch 338/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 410454176.0000 - val_loss: 2255915008.0000\n",
            "Epoch 339/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 421699712.0000 - val_loss: 2162027264.0000\n",
            "Epoch 340/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 413683712.0000 - val_loss: 2221570304.0000\n",
            "Epoch 341/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 412487008.0000 - val_loss: 2244830976.0000\n",
            "Epoch 342/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 410540416.0000 - val_loss: 2197284096.0000\n",
            "Epoch 343/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 410600896.0000 - val_loss: 2219498240.0000\n",
            "Epoch 344/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 409813984.0000 - val_loss: 2194312448.0000\n",
            "Epoch 345/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 407371872.0000 - val_loss: 2219399168.0000\n",
            "Epoch 346/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 412015392.0000 - val_loss: 2186302720.0000\n",
            "Epoch 347/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 414998176.0000 - val_loss: 2247895040.0000\n",
            "Epoch 348/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 420027072.0000 - val_loss: 2233968384.0000\n",
            "Epoch 349/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 408267840.0000 - val_loss: 2177341440.0000\n",
            "Epoch 350/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 406828096.0000 - val_loss: 2233830400.0000\n",
            "Epoch 351/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 420399936.0000 - val_loss: 2214782720.0000\n",
            "Epoch 352/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 405083392.0000 - val_loss: 2180665344.0000\n",
            "Epoch 353/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 407541344.0000 - val_loss: 2216618752.0000\n",
            "Epoch 354/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 404948544.0000 - val_loss: 2174399744.0000\n",
            "Epoch 355/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 404693280.0000 - val_loss: 2204444416.0000\n",
            "Epoch 356/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 402381792.0000 - val_loss: 2198211584.0000\n",
            "Epoch 357/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 403918176.0000 - val_loss: 2180530432.0000\n",
            "Epoch 358/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 402253792.0000 - val_loss: 2183155200.0000\n",
            "Epoch 359/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 404762752.0000 - val_loss: 2181321472.0000\n",
            "Epoch 360/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 401793472.0000 - val_loss: 2190252288.0000\n",
            "Epoch 361/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 398648512.0000 - val_loss: 2263384832.0000\n",
            "Epoch 362/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 402842528.0000 - val_loss: 2163209472.0000\n",
            "Epoch 363/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 399532320.0000 - val_loss: 2250117632.0000\n",
            "Epoch 364/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 396483168.0000 - val_loss: 2217379072.0000\n",
            "Epoch 365/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 397360480.0000 - val_loss: 2190597888.0000\n",
            "Epoch 366/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 399359424.0000 - val_loss: 2220389632.0000\n",
            "Epoch 367/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 396416864.0000 - val_loss: 2245569536.0000\n",
            "Epoch 368/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 401544128.0000 - val_loss: 2224649472.0000\n",
            "Epoch 369/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 397187744.0000 - val_loss: 2277372416.0000\n",
            "Epoch 370/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 394105568.0000 - val_loss: 2196676352.0000\n",
            "Epoch 371/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 399956608.0000 - val_loss: 2190593024.0000\n",
            "Epoch 372/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 395499008.0000 - val_loss: 2196091648.0000\n",
            "Epoch 373/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 393480192.0000 - val_loss: 2217931008.0000\n",
            "Epoch 374/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 399092672.0000 - val_loss: 2179689728.0000\n",
            "Epoch 375/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 394830176.0000 - val_loss: 2168154368.0000\n",
            "Epoch 376/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 392961696.0000 - val_loss: 2263236096.0000\n",
            "Epoch 377/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 391541056.0000 - val_loss: 2220277504.0000\n",
            "Epoch 378/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 391587200.0000 - val_loss: 2205819648.0000\n",
            "Epoch 379/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 391568640.0000 - val_loss: 2197113600.0000\n",
            "Epoch 380/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 391385760.0000 - val_loss: 2218636288.0000\n",
            "Epoch 381/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 396293952.0000 - val_loss: 2159600640.0000\n",
            "Epoch 382/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 389221472.0000 - val_loss: 2281933568.0000\n",
            "Epoch 383/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 391655424.0000 - val_loss: 2254042368.0000\n",
            "Epoch 384/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 389736800.0000 - val_loss: 2153281536.0000\n",
            "Epoch 385/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 387380960.0000 - val_loss: 2242118400.0000\n",
            "Epoch 386/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 395601152.0000 - val_loss: 2252636416.0000\n",
            "Epoch 387/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 387651040.0000 - val_loss: 2207741952.0000\n",
            "Epoch 388/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 386833408.0000 - val_loss: 2280630528.0000\n",
            "Epoch 389/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 387394272.0000 - val_loss: 2197395712.0000\n",
            "Epoch 390/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 386250784.0000 - val_loss: 2181472256.0000\n",
            "Epoch 391/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 384340000.0000 - val_loss: 2223506432.0000\n",
            "Epoch 392/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 391400544.0000 - val_loss: 2244205312.0000\n",
            "Epoch 393/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 382891840.0000 - val_loss: 2249441792.0000\n",
            "Epoch 394/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 384635360.0000 - val_loss: 2238330880.0000\n",
            "Epoch 395/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 382328480.0000 - val_loss: 2220921344.0000\n",
            "Epoch 396/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 384943840.0000 - val_loss: 2200504320.0000\n",
            "Epoch 397/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 384201600.0000 - val_loss: 2200274432.0000\n",
            "Epoch 398/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 390863264.0000 - val_loss: 2269968640.0000\n",
            "Epoch 399/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 380920096.0000 - val_loss: 2208506368.0000\n",
            "Epoch 400/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 377973568.0000 - val_loss: 2246377728.0000\n",
            "Epoch 401/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 387603072.0000 - val_loss: 2230052608.0000\n",
            "Epoch 402/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 380814912.0000 - val_loss: 2249054464.0000\n",
            "Epoch 403/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 384466784.0000 - val_loss: 2215136512.0000\n",
            "Epoch 404/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 378064256.0000 - val_loss: 2216258816.0000\n",
            "Epoch 405/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 378021632.0000 - val_loss: 2195998208.0000\n",
            "Epoch 406/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 376820224.0000 - val_loss: 2220034560.0000\n",
            "Epoch 407/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 381425920.0000 - val_loss: 2225874688.0000\n",
            "Epoch 408/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 377983392.0000 - val_loss: 2237416448.0000\n",
            "Epoch 409/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 384340768.0000 - val_loss: 2161800448.0000\n",
            "Epoch 410/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 383462816.0000 - val_loss: 2219184128.0000\n",
            "Epoch 411/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 379161920.0000 - val_loss: 2251759360.0000\n",
            "Epoch 412/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 377573728.0000 - val_loss: 2180476672.0000\n",
            "Epoch 413/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 380542944.0000 - val_loss: 2195593216.0000\n",
            "Epoch 414/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 379583232.0000 - val_loss: 2281982976.0000\n",
            "Epoch 415/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 375533408.0000 - val_loss: 2212610560.0000\n",
            "Epoch 416/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 374282496.0000 - val_loss: 2199083264.0000\n",
            "Epoch 417/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 381307232.0000 - val_loss: 2173597696.0000\n",
            "Epoch 418/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 376715616.0000 - val_loss: 2239514368.0000\n",
            "Epoch 419/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 371561056.0000 - val_loss: 2161646080.0000\n",
            "Epoch 420/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 375163072.0000 - val_loss: 2248430848.0000\n",
            "Epoch 421/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 380195456.0000 - val_loss: 2199736320.0000\n",
            "Epoch 422/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 367381536.0000 - val_loss: 2274313472.0000\n",
            "Epoch 423/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 370225056.0000 - val_loss: 2175794688.0000\n",
            "Epoch 424/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 369281216.0000 - val_loss: 2210677248.0000\n",
            "Epoch 425/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 368128768.0000 - val_loss: 2204163840.0000\n",
            "Epoch 426/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 369980480.0000 - val_loss: 2227993600.0000\n",
            "Epoch 427/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 369724608.0000 - val_loss: 2274517248.0000\n",
            "Epoch 428/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 375444480.0000 - val_loss: 2184401152.0000\n",
            "Epoch 429/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 375655360.0000 - val_loss: 2149209856.0000\n",
            "Epoch 430/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 368466272.0000 - val_loss: 2227204096.0000\n",
            "Epoch 431/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 370325344.0000 - val_loss: 2174388992.0000\n",
            "Epoch 432/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 365622368.0000 - val_loss: 2259579904.0000\n",
            "Epoch 433/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 366887840.0000 - val_loss: 2218744832.0000\n",
            "Epoch 434/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 369360576.0000 - val_loss: 2183667456.0000\n",
            "Epoch 435/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 365294272.0000 - val_loss: 2277863168.0000\n",
            "Epoch 436/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 369367616.0000 - val_loss: 2251432448.0000\n",
            "Epoch 437/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 364424096.0000 - val_loss: 2278016512.0000\n",
            "Epoch 438/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 366319392.0000 - val_loss: 2217391872.0000\n",
            "Epoch 439/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 363109440.0000 - val_loss: 2246618368.0000\n",
            "Epoch 440/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 364599008.0000 - val_loss: 2236657664.0000\n",
            "Epoch 441/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 366017728.0000 - val_loss: 2199901184.0000\n",
            "Epoch 442/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 367360000.0000 - val_loss: 2213234944.0000\n",
            "Epoch 443/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 366807392.0000 - val_loss: 2278677760.0000\n",
            "Epoch 444/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 363867136.0000 - val_loss: 2234103552.0000\n",
            "Epoch 445/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 360031872.0000 - val_loss: 2199330560.0000\n",
            "Epoch 446/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 361015840.0000 - val_loss: 2252268544.0000\n",
            "Epoch 447/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 359214272.0000 - val_loss: 2235092992.0000\n",
            "Epoch 448/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 360965184.0000 - val_loss: 2179067392.0000\n",
            "Epoch 449/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 362666400.0000 - val_loss: 2230497792.0000\n",
            "Epoch 450/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 361429792.0000 - val_loss: 2215174144.0000\n",
            "Epoch 451/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 371469920.0000 - val_loss: 2280823040.0000\n",
            "Epoch 452/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 356297696.0000 - val_loss: 2199049984.0000\n",
            "Epoch 453/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 363538816.0000 - val_loss: 2163100928.0000\n",
            "Epoch 454/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 355029760.0000 - val_loss: 2238149376.0000\n",
            "Epoch 455/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 355216544.0000 - val_loss: 2155444224.0000\n",
            "Epoch 456/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 357303104.0000 - val_loss: 2267779072.0000\n",
            "Epoch 457/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 358745280.0000 - val_loss: 2248360960.0000\n",
            "Epoch 458/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 356711392.0000 - val_loss: 2244584192.0000\n",
            "Epoch 459/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 358790592.0000 - val_loss: 2149479680.0000\n",
            "Epoch 460/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 355404480.0000 - val_loss: 2240323072.0000\n",
            "Epoch 461/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 353279808.0000 - val_loss: 2272092160.0000\n",
            "Epoch 462/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 353408000.0000 - val_loss: 2175095808.0000\n",
            "Epoch 463/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 352647968.0000 - val_loss: 2244513792.0000\n",
            "Epoch 464/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 355605376.0000 - val_loss: 2269907712.0000\n",
            "Epoch 465/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 351227776.0000 - val_loss: 2196846336.0000\n",
            "Epoch 466/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 350852128.0000 - val_loss: 2216990464.0000\n",
            "Epoch 467/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 351012192.0000 - val_loss: 2231376896.0000\n",
            "Epoch 468/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 349067296.0000 - val_loss: 2199098368.0000\n",
            "Epoch 469/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 352527776.0000 - val_loss: 2235947264.0000\n",
            "Epoch 470/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 352834272.0000 - val_loss: 2241573888.0000\n",
            "Epoch 471/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 356629984.0000 - val_loss: 2197431040.0000\n",
            "Epoch 472/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 355682656.0000 - val_loss: 2235077888.0000\n",
            "Epoch 473/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 351899200.0000 - val_loss: 2239326720.0000\n",
            "Epoch 474/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 348386080.0000 - val_loss: 2272946176.0000\n",
            "Epoch 475/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 356094816.0000 - val_loss: 2300892416.0000\n",
            "Epoch 476/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 350418176.0000 - val_loss: 2244326400.0000\n",
            "Epoch 477/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 349832096.0000 - val_loss: 2162916096.0000\n",
            "Epoch 478/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 345494976.0000 - val_loss: 2248322048.0000\n",
            "Epoch 479/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 350495872.0000 - val_loss: 2241851904.0000\n",
            "Epoch 480/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 347379488.0000 - val_loss: 2189256704.0000\n",
            "Epoch 481/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 348037984.0000 - val_loss: 2200456704.0000\n",
            "Epoch 482/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 349848096.0000 - val_loss: 2183966208.0000\n",
            "Epoch 483/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 341464544.0000 - val_loss: 2229516032.0000\n",
            "Epoch 484/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 348349056.0000 - val_loss: 2216032768.0000\n",
            "Epoch 485/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 341607936.0000 - val_loss: 2234984960.0000\n",
            "Epoch 486/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 342274560.0000 - val_loss: 2154163456.0000\n",
            "Epoch 487/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 352532128.0000 - val_loss: 2171201280.0000\n",
            "Epoch 488/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 347390912.0000 - val_loss: 2215869184.0000\n",
            "Epoch 489/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 344272096.0000 - val_loss: 2290136320.0000\n",
            "Epoch 490/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 339067936.0000 - val_loss: 2218259968.0000\n",
            "Epoch 491/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 342639296.0000 - val_loss: 2222164736.0000\n",
            "Epoch 492/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 343745472.0000 - val_loss: 2286789888.0000\n",
            "Epoch 493/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 340676992.0000 - val_loss: 2206581248.0000\n",
            "Epoch 494/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 341352736.0000 - val_loss: 2226384384.0000\n",
            "Epoch 495/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 339875424.0000 - val_loss: 2302787840.0000\n",
            "Epoch 496/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 340053696.0000 - val_loss: 2232766464.0000\n",
            "Epoch 497/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 337054912.0000 - val_loss: 2278405888.0000\n",
            "Epoch 498/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 344111424.0000 - val_loss: 2280576256.0000\n",
            "Epoch 499/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 336516160.0000 - val_loss: 2190632704.0000\n",
            "Epoch 500/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 340374592.0000 - val_loss: 2183665920.0000\n",
            "Epoch 501/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 339218272.0000 - val_loss: 2223792384.0000\n",
            "Epoch 502/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 337672672.0000 - val_loss: 2205058560.0000\n",
            "Epoch 503/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 340521920.0000 - val_loss: 2198037504.0000\n",
            "Epoch 504/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 334686656.0000 - val_loss: 2213041152.0000\n",
            "Epoch 505/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 335361696.0000 - val_loss: 2242478592.0000\n",
            "Epoch 506/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 333590208.0000 - val_loss: 2263890432.0000\n",
            "Epoch 507/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 335806464.0000 - val_loss: 2209356032.0000\n",
            "Epoch 508/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 341318528.0000 - val_loss: 2243689216.0000\n",
            "Epoch 509/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 332169440.0000 - val_loss: 2274990336.0000\n",
            "Epoch 510/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 337755712.0000 - val_loss: 2245669120.0000\n",
            "Epoch 511/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 340981920.0000 - val_loss: 2217767168.0000\n",
            "Epoch 512/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 331616832.0000 - val_loss: 2221302272.0000\n",
            "Epoch 513/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 336117696.0000 - val_loss: 2290240256.0000\n",
            "Epoch 514/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 338743968.0000 - val_loss: 2192460544.0000\n",
            "Epoch 515/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 332408672.0000 - val_loss: 2241834496.0000\n",
            "Epoch 516/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 329301760.0000 - val_loss: 2211311616.0000\n",
            "Epoch 517/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 331070944.0000 - val_loss: 2274827776.0000\n",
            "Epoch 518/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 329054656.0000 - val_loss: 2247301632.0000\n",
            "Epoch 519/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 328656576.0000 - val_loss: 2228607232.0000\n",
            "Epoch 520/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 330325152.0000 - val_loss: 2244034304.0000\n",
            "Epoch 521/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 334726816.0000 - val_loss: 2205690880.0000\n",
            "Epoch 522/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 328623104.0000 - val_loss: 2200508928.0000\n",
            "Epoch 523/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 330745024.0000 - val_loss: 2169753344.0000\n",
            "Epoch 524/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 336481056.0000 - val_loss: 2164087040.0000\n",
            "Epoch 525/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 335546752.0000 - val_loss: 2186709504.0000\n",
            "Epoch 526/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 336521568.0000 - val_loss: 2162231808.0000\n",
            "Epoch 527/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 330346144.0000 - val_loss: 2208752896.0000\n",
            "Epoch 528/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 325945472.0000 - val_loss: 2268261632.0000\n",
            "Epoch 529/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 325775168.0000 - val_loss: 2185664768.0000\n",
            "Epoch 530/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 327445952.0000 - val_loss: 2226686976.0000\n",
            "Epoch 531/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 330506592.0000 - val_loss: 2190042624.0000\n",
            "Epoch 532/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 332492512.0000 - val_loss: 2188720384.0000\n",
            "Epoch 533/1000\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 332441600.0000 - val_loss: 2193728768.0000\n",
            "Epoch 534/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 321954240.0000 - val_loss: 2255840000.0000\n",
            "Epoch 535/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 324250208.0000 - val_loss: 2319184896.0000\n",
            "Epoch 536/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 321181184.0000 - val_loss: 2261142272.0000\n",
            "Epoch 537/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 320692384.0000 - val_loss: 2257696512.0000\n",
            "Epoch 538/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 325631808.0000 - val_loss: 2287490048.0000\n",
            "Epoch 539/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 320364896.0000 - val_loss: 2255479808.0000\n",
            "Epoch 540/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 321118464.0000 - val_loss: 2224910592.0000\n",
            "Epoch 541/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 319718592.0000 - val_loss: 2267417344.0000\n",
            "Epoch 542/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 323008256.0000 - val_loss: 2250693120.0000\n",
            "Epoch 543/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 327148000.0000 - val_loss: 2224676608.0000\n",
            "Epoch 544/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 316471296.0000 - val_loss: 2329597696.0000\n",
            "Epoch 545/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 325802880.0000 - val_loss: 2325065984.0000\n",
            "Epoch 546/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 320296160.0000 - val_loss: 2202356736.0000\n",
            "Epoch 547/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 325210240.0000 - val_loss: 2189949440.0000\n",
            "Epoch 548/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 325289088.0000 - val_loss: 2169870848.0000\n",
            "Epoch 549/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 321062560.0000 - val_loss: 2251008256.0000\n",
            "Epoch 550/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 318465024.0000 - val_loss: 2221188864.0000\n",
            "Epoch 551/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 318663936.0000 - val_loss: 2337560832.0000\n",
            "Epoch 552/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 319601984.0000 - val_loss: 2255687680.0000\n",
            "Epoch 553/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 312399456.0000 - val_loss: 2289888768.0000\n",
            "Epoch 554/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 316642016.0000 - val_loss: 2259592960.0000\n",
            "Epoch 555/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 317806752.0000 - val_loss: 2271939328.0000\n",
            "Epoch 556/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 317641344.0000 - val_loss: 2217559808.0000\n",
            "Epoch 557/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 313367072.0000 - val_loss: 2224507904.0000\n",
            "Epoch 558/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 322209504.0000 - val_loss: 2372763904.0000\n",
            "Epoch 559/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 315722176.0000 - val_loss: 2284729088.0000\n",
            "Epoch 560/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 314091936.0000 - val_loss: 2256924160.0000\n",
            "Epoch 561/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 310234336.0000 - val_loss: 2274904064.0000\n",
            "Epoch 562/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 314066816.0000 - val_loss: 2320790784.0000\n",
            "Epoch 563/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 317116352.0000 - val_loss: 2258306304.0000\n",
            "Epoch 564/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 311495200.0000 - val_loss: 2342976000.0000\n",
            "Epoch 565/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 309991904.0000 - val_loss: 2276142592.0000\n",
            "Epoch 566/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 312150592.0000 - val_loss: 2327201024.0000\n",
            "Epoch 567/1000\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 312202432.0000 - val_loss: 2322018048.0000\n",
            "Epoch 568/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 307030592.0000 - val_loss: 2246920192.0000\n",
            "Epoch 569/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 316395680.0000 - val_loss: 2236796416.0000\n",
            "Epoch 570/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 312912992.0000 - val_loss: 2288754688.0000\n",
            "Epoch 571/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 307532896.0000 - val_loss: 2208931328.0000\n",
            "Epoch 572/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 311771840.0000 - val_loss: 2246733824.0000\n",
            "Epoch 573/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 315139616.0000 - val_loss: 2300919552.0000\n",
            "Epoch 574/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 311562496.0000 - val_loss: 2306085376.0000\n",
            "Epoch 575/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 306255904.0000 - val_loss: 2321696768.0000\n",
            "Epoch 576/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 313506624.0000 - val_loss: 2260146688.0000\n",
            "Epoch 577/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 312121376.0000 - val_loss: 2221961216.0000\n",
            "Epoch 578/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 310467904.0000 - val_loss: 2317022208.0000\n",
            "Epoch 579/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 305071200.0000 - val_loss: 2386730496.0000\n",
            "Epoch 580/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 307794560.0000 - val_loss: 2298883584.0000\n",
            "Epoch 581/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 307390816.0000 - val_loss: 2346264320.0000\n",
            "Epoch 582/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 302969024.0000 - val_loss: 2300650752.0000\n",
            "Epoch 583/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 302616864.0000 - val_loss: 2337975808.0000\n",
            "Epoch 584/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 306620512.0000 - val_loss: 2291537152.0000\n",
            "Epoch 585/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 302996608.0000 - val_loss: 2330184192.0000\n",
            "Epoch 586/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 307119456.0000 - val_loss: 2292145152.0000\n",
            "Epoch 587/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 305257248.0000 - val_loss: 2368802304.0000\n",
            "Epoch 588/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 308619712.0000 - val_loss: 2377869568.0000\n",
            "Epoch 589/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 304280960.0000 - val_loss: 2286854144.0000\n",
            "Epoch 590/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 300991680.0000 - val_loss: 2301154560.0000\n",
            "Epoch 591/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 301050592.0000 - val_loss: 2315134720.0000\n",
            "Epoch 592/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 299321376.0000 - val_loss: 2271912448.0000\n",
            "Epoch 593/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 298987648.0000 - val_loss: 2331527936.0000\n",
            "Epoch 594/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 304085792.0000 - val_loss: 2342169344.0000\n",
            "Epoch 595/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 301888832.0000 - val_loss: 2284045056.0000\n",
            "Epoch 596/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 304080832.0000 - val_loss: 2299741440.0000\n",
            "Epoch 597/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 297206176.0000 - val_loss: 2279538944.0000\n",
            "Epoch 598/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 299244160.0000 - val_loss: 2312481536.0000\n",
            "Epoch 599/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 301944576.0000 - val_loss: 2343288576.0000\n",
            "Epoch 600/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 297202944.0000 - val_loss: 2291379712.0000\n",
            "Epoch 601/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 296608384.0000 - val_loss: 2263210752.0000\n",
            "Epoch 602/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 294864704.0000 - val_loss: 2367938560.0000\n",
            "Epoch 603/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 299523648.0000 - val_loss: 2331663360.0000\n",
            "Epoch 604/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 295429792.0000 - val_loss: 2349987072.0000\n",
            "Epoch 605/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 294219872.0000 - val_loss: 2295654144.0000\n",
            "Epoch 606/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 294667104.0000 - val_loss: 2329784320.0000\n",
            "Epoch 607/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 294909728.0000 - val_loss: 2320575744.0000\n",
            "Epoch 608/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 293297376.0000 - val_loss: 2290652160.0000\n",
            "Epoch 609/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 291967104.0000 - val_loss: 2257017600.0000\n",
            "Epoch 610/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 296156224.0000 - val_loss: 2305217280.0000\n",
            "Epoch 611/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 294770528.0000 - val_loss: 2331180544.0000\n",
            "Epoch 612/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 300333408.0000 - val_loss: 2345237760.0000\n",
            "Epoch 613/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 297102688.0000 - val_loss: 2422180864.0000\n",
            "Epoch 614/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 301599296.0000 - val_loss: 2368920832.0000\n",
            "Epoch 615/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 295920224.0000 - val_loss: 2298231296.0000\n",
            "Epoch 616/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 293076928.0000 - val_loss: 2319769600.0000\n",
            "Epoch 617/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 294662240.0000 - val_loss: 2279597312.0000\n",
            "Epoch 618/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 297930592.0000 - val_loss: 2298096896.0000\n",
            "Epoch 619/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 290885504.0000 - val_loss: 2335416064.0000\n",
            "Epoch 620/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 288536544.0000 - val_loss: 2358191872.0000\n",
            "Epoch 621/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 289331552.0000 - val_loss: 2326494720.0000\n",
            "Epoch 622/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 296291168.0000 - val_loss: 2346440960.0000\n",
            "Epoch 623/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 289004864.0000 - val_loss: 2285843456.0000\n",
            "Epoch 624/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 289371584.0000 - val_loss: 2342630656.0000\n",
            "Epoch 625/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 290358208.0000 - val_loss: 2352743424.0000\n",
            "Epoch 626/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 299926432.0000 - val_loss: 2342865408.0000\n",
            "Epoch 627/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 290760576.0000 - val_loss: 2360333824.0000\n",
            "Epoch 628/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 286202624.0000 - val_loss: 2361734400.0000\n",
            "Epoch 629/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 298005952.0000 - val_loss: 2457885696.0000\n",
            "Epoch 630/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 292467712.0000 - val_loss: 2352155648.0000\n",
            "Epoch 631/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 289039936.0000 - val_loss: 2326365952.0000\n",
            "Epoch 632/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 288656608.0000 - val_loss: 2415443456.0000\n",
            "Epoch 633/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 288029472.0000 - val_loss: 2394270464.0000\n",
            "Epoch 634/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 287470368.0000 - val_loss: 2285910272.0000\n",
            "Epoch 635/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 284537824.0000 - val_loss: 2350564352.0000\n",
            "Epoch 636/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 288558080.0000 - val_loss: 2342778112.0000\n",
            "Epoch 637/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 281482048.0000 - val_loss: 2427550976.0000\n",
            "Epoch 638/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 289053280.0000 - val_loss: 2373283840.0000\n",
            "Epoch 639/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 280692480.0000 - val_loss: 2379163392.0000\n",
            "Epoch 640/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 281332896.0000 - val_loss: 2366078464.0000\n",
            "Epoch 641/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 285335584.0000 - val_loss: 2315154944.0000\n",
            "Epoch 642/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 283877952.0000 - val_loss: 2307657472.0000\n",
            "Epoch 643/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 280929920.0000 - val_loss: 2348416512.0000\n",
            "Epoch 644/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 286963168.0000 - val_loss: 2404303616.0000\n",
            "Epoch 645/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 281281088.0000 - val_loss: 2381392896.0000\n",
            "Epoch 646/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 280699520.0000 - val_loss: 2303983360.0000\n",
            "Epoch 647/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 276898496.0000 - val_loss: 2396883456.0000\n",
            "Epoch 648/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 278987616.0000 - val_loss: 2408159744.0000\n",
            "Epoch 649/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 278519360.0000 - val_loss: 2357248256.0000\n",
            "Epoch 650/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 278164320.0000 - val_loss: 2393410304.0000\n",
            "Epoch 651/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 276630592.0000 - val_loss: 2365421056.0000\n",
            "Epoch 652/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 279143968.0000 - val_loss: 2348969728.0000\n",
            "Epoch 653/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 288103936.0000 - val_loss: 2364947968.0000\n",
            "Epoch 654/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 277246816.0000 - val_loss: 2338021376.0000\n",
            "Epoch 655/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 275780000.0000 - val_loss: 2342489600.0000\n",
            "Epoch 656/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 277129632.0000 - val_loss: 2365403392.0000\n",
            "Epoch 657/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 273986944.0000 - val_loss: 2339380736.0000\n",
            "Epoch 658/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 276831680.0000 - val_loss: 2379832064.0000\n",
            "Epoch 659/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 275676832.0000 - val_loss: 2377716480.0000\n",
            "Epoch 660/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 275817472.0000 - val_loss: 2360742400.0000\n",
            "Epoch 661/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 276187264.0000 - val_loss: 2365225984.0000\n",
            "Epoch 662/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 272818976.0000 - val_loss: 2438513664.0000\n",
            "Epoch 663/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 273121632.0000 - val_loss: 2376644608.0000\n",
            "Epoch 664/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 274718304.0000 - val_loss: 2352922112.0000\n",
            "Epoch 665/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 273995776.0000 - val_loss: 2372788224.0000\n",
            "Epoch 666/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 273209632.0000 - val_loss: 2431389696.0000\n",
            "Epoch 667/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 275164032.0000 - val_loss: 2414471168.0000\n",
            "Epoch 668/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 272984416.0000 - val_loss: 2420062464.0000\n",
            "Epoch 669/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 269974528.0000 - val_loss: 2428470784.0000\n",
            "Epoch 670/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 273552896.0000 - val_loss: 2480663552.0000\n",
            "Epoch 671/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 272537920.0000 - val_loss: 2425625344.0000\n",
            "Epoch 672/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 271305312.0000 - val_loss: 2410139392.0000\n",
            "Epoch 673/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 268022720.0000 - val_loss: 2365445120.0000\n",
            "Epoch 674/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 274420416.0000 - val_loss: 2429649152.0000\n",
            "Epoch 675/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 275383296.0000 - val_loss: 2363371776.0000\n",
            "Epoch 676/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 272137152.0000 - val_loss: 2380630784.0000\n",
            "Epoch 677/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 266591744.0000 - val_loss: 2373607936.0000\n",
            "Epoch 678/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 268290240.0000 - val_loss: 2356612864.0000\n",
            "Epoch 679/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 272004320.0000 - val_loss: 2395832320.0000\n",
            "Epoch 680/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 264753088.0000 - val_loss: 2447702016.0000\n",
            "Epoch 681/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 272308544.0000 - val_loss: 2457378048.0000\n",
            "Epoch 682/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 265515792.0000 - val_loss: 2389861376.0000\n",
            "Epoch 683/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 267339248.0000 - val_loss: 2403215872.0000\n",
            "Epoch 684/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 263033280.0000 - val_loss: 2415037184.0000\n",
            "Epoch 685/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 266789056.0000 - val_loss: 2407736576.0000\n",
            "Epoch 686/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 263349968.0000 - val_loss: 2445186304.0000\n",
            "Epoch 687/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 265591264.0000 - val_loss: 2420072960.0000\n",
            "Epoch 688/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 264350176.0000 - val_loss: 2441169152.0000\n",
            "Epoch 689/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 262099840.0000 - val_loss: 2379251200.0000\n",
            "Epoch 690/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 260138336.0000 - val_loss: 2478902528.0000\n",
            "Epoch 691/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 268971296.0000 - val_loss: 2413080064.0000\n",
            "Epoch 692/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 262681696.0000 - val_loss: 2389434624.0000\n",
            "Epoch 693/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 267418832.0000 - val_loss: 2400884224.0000\n",
            "Epoch 694/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 264446880.0000 - val_loss: 2493313792.0000\n",
            "Epoch 695/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 257912016.0000 - val_loss: 2358742016.0000\n",
            "Epoch 696/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 264611904.0000 - val_loss: 2368798720.0000\n",
            "Epoch 697/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 258577248.0000 - val_loss: 2503601920.0000\n",
            "Epoch 698/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 260988256.0000 - val_loss: 2510899712.0000\n",
            "Epoch 699/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 262821472.0000 - val_loss: 2419592448.0000\n",
            "Epoch 700/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 257593008.0000 - val_loss: 2466699008.0000\n",
            "Epoch 701/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 259207792.0000 - val_loss: 2428138752.0000\n",
            "Epoch 702/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 261865984.0000 - val_loss: 2500411136.0000\n",
            "Epoch 703/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 267883168.0000 - val_loss: 2522275072.0000\n",
            "Epoch 704/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 257793520.0000 - val_loss: 2407899648.0000\n",
            "Epoch 705/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 257898352.0000 - val_loss: 2477873920.0000\n",
            "Epoch 706/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 256943568.0000 - val_loss: 2411257344.0000\n",
            "Epoch 707/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 257629200.0000 - val_loss: 2382667776.0000\n",
            "Epoch 708/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 258023392.0000 - val_loss: 2422601216.0000\n",
            "Epoch 709/1000\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 253396704.0000 - val_loss: 2480126208.0000\n",
            "Epoch 710/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 253037616.0000 - val_loss: 2378120192.0000\n",
            "Epoch 711/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 257954304.0000 - val_loss: 2421532928.0000\n",
            "Epoch 712/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 253858976.0000 - val_loss: 2407449600.0000\n",
            "Epoch 713/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 257622016.0000 - val_loss: 2445879296.0000\n",
            "Epoch 714/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 253728128.0000 - val_loss: 2430032384.0000\n",
            "Epoch 715/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 254704176.0000 - val_loss: 2457530112.0000\n",
            "Epoch 716/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 252229152.0000 - val_loss: 2433337600.0000\n",
            "Epoch 717/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 255827904.0000 - val_loss: 2395017728.0000\n",
            "Epoch 718/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 255254272.0000 - val_loss: 2367059968.0000\n",
            "Epoch 719/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 254283328.0000 - val_loss: 2406837248.0000\n",
            "Epoch 720/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 252206368.0000 - val_loss: 2486291200.0000\n",
            "Epoch 721/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 252179392.0000 - val_loss: 2512608512.0000\n",
            "Epoch 722/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 251845984.0000 - val_loss: 2479098112.0000\n",
            "Epoch 723/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 254219168.0000 - val_loss: 2485308672.0000\n",
            "Epoch 724/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 247487984.0000 - val_loss: 2426340352.0000\n",
            "Epoch 725/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 248972240.0000 - val_loss: 2489281792.0000\n",
            "Epoch 726/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 247865200.0000 - val_loss: 2484149248.0000\n",
            "Epoch 727/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 247743392.0000 - val_loss: 2467145728.0000\n",
            "Epoch 728/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 249953568.0000 - val_loss: 2421532416.0000\n",
            "Epoch 729/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 246651808.0000 - val_loss: 2480814080.0000\n",
            "Epoch 730/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 247682176.0000 - val_loss: 2359019520.0000\n",
            "Epoch 731/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 261462192.0000 - val_loss: 2372168704.0000\n",
            "Epoch 732/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 251569984.0000 - val_loss: 2536538112.0000\n",
            "Epoch 733/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 247986512.0000 - val_loss: 2460963840.0000\n",
            "Epoch 734/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 248659152.0000 - val_loss: 2403435776.0000\n",
            "Epoch 735/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 244183744.0000 - val_loss: 2505683968.0000\n",
            "Epoch 736/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 242364704.0000 - val_loss: 2466466816.0000\n",
            "Epoch 737/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 242776064.0000 - val_loss: 2504444672.0000\n",
            "Epoch 738/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 247944768.0000 - val_loss: 2518596864.0000\n",
            "Epoch 739/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 240800416.0000 - val_loss: 2461829888.0000\n",
            "Epoch 740/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 245467984.0000 - val_loss: 2462535424.0000\n",
            "Epoch 741/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 245987552.0000 - val_loss: 2447210240.0000\n",
            "Epoch 742/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 240942704.0000 - val_loss: 2456606208.0000\n",
            "Epoch 743/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 242269168.0000 - val_loss: 2476087552.0000\n",
            "Epoch 744/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 240682528.0000 - val_loss: 2481698048.0000\n",
            "Epoch 745/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 242159104.0000 - val_loss: 2461306368.0000\n",
            "Epoch 746/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 240280224.0000 - val_loss: 2528952320.0000\n",
            "Epoch 747/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 239493408.0000 - val_loss: 2509652992.0000\n",
            "Epoch 748/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 239519232.0000 - val_loss: 2526269184.0000\n",
            "Epoch 749/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 241407888.0000 - val_loss: 2554110720.0000\n",
            "Epoch 750/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 244192992.0000 - val_loss: 2517044480.0000\n",
            "Epoch 751/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 243718544.0000 - val_loss: 2527996416.0000\n",
            "Epoch 752/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 238157200.0000 - val_loss: 2515412480.0000\n",
            "Epoch 753/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 236491600.0000 - val_loss: 2579069440.0000\n",
            "Epoch 754/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 238232144.0000 - val_loss: 2533038336.0000\n",
            "Epoch 755/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 237963072.0000 - val_loss: 2525045504.0000\n",
            "Epoch 756/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 234898640.0000 - val_loss: 2473431552.0000\n",
            "Epoch 757/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 239057648.0000 - val_loss: 2448343808.0000\n",
            "Epoch 758/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 232417728.0000 - val_loss: 2547513856.0000\n",
            "Epoch 759/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 244165872.0000 - val_loss: 2657921280.0000\n",
            "Epoch 760/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 241994928.0000 - val_loss: 2591110656.0000\n",
            "Epoch 761/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 236354128.0000 - val_loss: 2655146752.0000\n",
            "Epoch 762/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 236135936.0000 - val_loss: 2510619648.0000\n",
            "Epoch 763/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 236206976.0000 - val_loss: 2545242624.0000\n",
            "Epoch 764/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 232759008.0000 - val_loss: 2617796096.0000\n",
            "Epoch 765/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 245028672.0000 - val_loss: 2548826368.0000\n",
            "Epoch 766/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 236188240.0000 - val_loss: 2557064448.0000\n",
            "Epoch 767/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 239058608.0000 - val_loss: 2505001216.0000\n",
            "Epoch 768/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 234876256.0000 - val_loss: 2553594112.0000\n",
            "Epoch 769/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 230892496.0000 - val_loss: 2481323520.0000\n",
            "Epoch 770/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 236143664.0000 - val_loss: 2460084224.0000\n",
            "Epoch 771/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 231751216.0000 - val_loss: 2554888960.0000\n",
            "Epoch 772/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 230948656.0000 - val_loss: 2533016832.0000\n",
            "Epoch 773/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 229112640.0000 - val_loss: 2574584064.0000\n",
            "Epoch 774/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 230659696.0000 - val_loss: 2543806208.0000\n",
            "Epoch 775/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 228854560.0000 - val_loss: 2481576192.0000\n",
            "Epoch 776/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 231642272.0000 - val_loss: 2529047552.0000\n",
            "Epoch 777/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 227714032.0000 - val_loss: 2548663040.0000\n",
            "Epoch 778/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 230634784.0000 - val_loss: 2606663680.0000\n",
            "Epoch 779/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 248343088.0000 - val_loss: 2630338816.0000\n",
            "Epoch 780/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 230412256.0000 - val_loss: 2602633984.0000\n",
            "Epoch 781/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 225732144.0000 - val_loss: 2582606592.0000\n",
            "Epoch 782/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 229230080.0000 - val_loss: 2665863168.0000\n",
            "Epoch 783/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 231129680.0000 - val_loss: 2590580224.0000\n",
            "Epoch 784/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 229165952.0000 - val_loss: 2643070720.0000\n",
            "Epoch 785/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 228550304.0000 - val_loss: 2508403968.0000\n",
            "Epoch 786/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 224545712.0000 - val_loss: 2605986816.0000\n",
            "Epoch 787/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 225479392.0000 - val_loss: 2502085120.0000\n",
            "Epoch 788/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 229474928.0000 - val_loss: 2547344384.0000\n",
            "Epoch 789/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 225561696.0000 - val_loss: 2532155392.0000\n",
            "Epoch 790/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 226095696.0000 - val_loss: 2601930752.0000\n",
            "Epoch 791/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 225667872.0000 - val_loss: 2585981440.0000\n",
            "Epoch 792/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 223734496.0000 - val_loss: 2618336768.0000\n",
            "Epoch 793/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 225005408.0000 - val_loss: 2571905280.0000\n",
            "Epoch 794/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 220830800.0000 - val_loss: 2560805120.0000\n",
            "Epoch 795/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 223554320.0000 - val_loss: 2638926336.0000\n",
            "Epoch 796/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 222256640.0000 - val_loss: 2547687936.0000\n",
            "Epoch 797/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 219229744.0000 - val_loss: 2614656000.0000\n",
            "Epoch 798/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 220042144.0000 - val_loss: 2634324736.0000\n",
            "Epoch 799/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 222865872.0000 - val_loss: 2637671936.0000\n",
            "Epoch 800/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 219882976.0000 - val_loss: 2653722880.0000\n",
            "Epoch 801/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 219548704.0000 - val_loss: 2666302208.0000\n",
            "Epoch 802/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 222327632.0000 - val_loss: 2605979392.0000\n",
            "Epoch 803/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 219983904.0000 - val_loss: 2606865920.0000\n",
            "Epoch 804/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 221522416.0000 - val_loss: 2505083648.0000\n",
            "Epoch 805/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 226511120.0000 - val_loss: 2703778304.0000\n",
            "Epoch 806/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 218354640.0000 - val_loss: 2671234816.0000\n",
            "Epoch 807/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 212731648.0000 - val_loss: 2505554944.0000\n",
            "Epoch 808/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 217395920.0000 - val_loss: 2692133632.0000\n",
            "Epoch 809/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 216934352.0000 - val_loss: 2587343872.0000\n",
            "Epoch 810/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 216139536.0000 - val_loss: 2624100608.0000\n",
            "Epoch 811/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 215416336.0000 - val_loss: 2611640832.0000\n",
            "Epoch 812/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 215206288.0000 - val_loss: 2644409600.0000\n",
            "Epoch 813/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 213689328.0000 - val_loss: 2606460416.0000\n",
            "Epoch 814/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 215539808.0000 - val_loss: 2652266496.0000\n",
            "Epoch 815/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 217420400.0000 - val_loss: 2646445056.0000\n",
            "Epoch 816/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 212929040.0000 - val_loss: 2604080896.0000\n",
            "Epoch 817/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 215413056.0000 - val_loss: 2553085696.0000\n",
            "Epoch 818/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 212631056.0000 - val_loss: 2635405824.0000\n",
            "Epoch 819/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 211614240.0000 - val_loss: 2589697280.0000\n",
            "Epoch 820/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 211350608.0000 - val_loss: 2597835520.0000\n",
            "Epoch 821/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 211222592.0000 - val_loss: 2701839104.0000\n",
            "Epoch 822/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 213373792.0000 - val_loss: 2643090176.0000\n",
            "Epoch 823/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 213538864.0000 - val_loss: 2688816384.0000\n",
            "Epoch 824/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 211048544.0000 - val_loss: 2594189824.0000\n",
            "Epoch 825/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 216542096.0000 - val_loss: 2542490112.0000\n",
            "Epoch 826/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 210479440.0000 - val_loss: 2650398720.0000\n",
            "Epoch 827/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 209152304.0000 - val_loss: 2710140928.0000\n",
            "Epoch 828/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 213208800.0000 - val_loss: 2702510848.0000\n",
            "Epoch 829/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 209372096.0000 - val_loss: 2633926400.0000\n",
            "Epoch 830/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 211914624.0000 - val_loss: 2621690880.0000\n",
            "Epoch 831/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 207789504.0000 - val_loss: 2664655616.0000\n",
            "Epoch 832/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 207380816.0000 - val_loss: 2609016320.0000\n",
            "Epoch 833/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 206791216.0000 - val_loss: 2701028864.0000\n",
            "Epoch 834/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 209502640.0000 - val_loss: 2735546368.0000\n",
            "Epoch 835/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 212481488.0000 - val_loss: 2616294400.0000\n",
            "Epoch 836/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 207092224.0000 - val_loss: 2679838720.0000\n",
            "Epoch 837/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 205445664.0000 - val_loss: 2710825472.0000\n",
            "Epoch 838/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 204684336.0000 - val_loss: 2631200256.0000\n",
            "Epoch 839/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 208701552.0000 - val_loss: 2657188352.0000\n",
            "Epoch 840/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 204757744.0000 - val_loss: 2697031168.0000\n",
            "Epoch 841/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 203111584.0000 - val_loss: 2629493248.0000\n",
            "Epoch 842/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 206469600.0000 - val_loss: 2689169920.0000\n",
            "Epoch 843/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 202136000.0000 - val_loss: 2720430848.0000\n",
            "Epoch 844/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 202995728.0000 - val_loss: 2594360832.0000\n",
            "Epoch 845/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 210223856.0000 - val_loss: 2688163584.0000\n",
            "Epoch 846/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 203067760.0000 - val_loss: 2668195072.0000\n",
            "Epoch 847/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 203657088.0000 - val_loss: 2673579776.0000\n",
            "Epoch 848/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 201313152.0000 - val_loss: 2654297856.0000\n",
            "Epoch 849/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 201731440.0000 - val_loss: 2690347520.0000\n",
            "Epoch 850/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 202952592.0000 - val_loss: 2673474304.0000\n",
            "Epoch 851/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 199552848.0000 - val_loss: 2724582144.0000\n",
            "Epoch 852/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 199513632.0000 - val_loss: 2649933568.0000\n",
            "Epoch 853/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 198820720.0000 - val_loss: 2603816704.0000\n",
            "Epoch 854/1000\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 200632704.0000 - val_loss: 2737768704.0000\n",
            "Epoch 855/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 199424736.0000 - val_loss: 2688859136.0000\n",
            "Epoch 856/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 197687680.0000 - val_loss: 2636735744.0000\n",
            "Epoch 857/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 198194032.0000 - val_loss: 2693701376.0000\n",
            "Epoch 858/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 200360336.0000 - val_loss: 2663207936.0000\n",
            "Epoch 859/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 198484160.0000 - val_loss: 2711221504.0000\n",
            "Epoch 860/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 197770928.0000 - val_loss: 2646424576.0000\n",
            "Epoch 861/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 197354624.0000 - val_loss: 2736584704.0000\n",
            "Epoch 862/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 198968976.0000 - val_loss: 2657412864.0000\n",
            "Epoch 863/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 194800800.0000 - val_loss: 2799128832.0000\n",
            "Epoch 864/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 196699280.0000 - val_loss: 2741884928.0000\n",
            "Epoch 865/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 193913792.0000 - val_loss: 2797401600.0000\n",
            "Epoch 866/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 197763392.0000 - val_loss: 2758493184.0000\n",
            "Epoch 867/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 193603344.0000 - val_loss: 2768805376.0000\n",
            "Epoch 868/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 195239760.0000 - val_loss: 2746342144.0000\n",
            "Epoch 869/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 202264288.0000 - val_loss: 2633944832.0000\n",
            "Epoch 870/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 203137088.0000 - val_loss: 2824124160.0000\n",
            "Epoch 871/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 193425120.0000 - val_loss: 2662219264.0000\n",
            "Epoch 872/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 193229280.0000 - val_loss: 2736417536.0000\n",
            "Epoch 873/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 192243344.0000 - val_loss: 2649747968.0000\n",
            "Epoch 874/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 193611120.0000 - val_loss: 2750683392.0000\n",
            "Epoch 875/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 188428080.0000 - val_loss: 2834428928.0000\n",
            "Epoch 876/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 191595440.0000 - val_loss: 2755254016.0000\n",
            "Epoch 877/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 188301040.0000 - val_loss: 2761817600.0000\n",
            "Epoch 878/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 188368864.0000 - val_loss: 2819550720.0000\n",
            "Epoch 879/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 192618112.0000 - val_loss: 2827620096.0000\n",
            "Epoch 880/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 189126432.0000 - val_loss: 2796624384.0000\n",
            "Epoch 881/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 189212016.0000 - val_loss: 2780030720.0000\n",
            "Epoch 882/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 189175728.0000 - val_loss: 2787546112.0000\n",
            "Epoch 883/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 188795312.0000 - val_loss: 2838089728.0000\n",
            "Epoch 884/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 186641712.0000 - val_loss: 2786707200.0000\n",
            "Epoch 885/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 187497760.0000 - val_loss: 2817688576.0000\n",
            "Epoch 886/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 187396928.0000 - val_loss: 2899351808.0000\n",
            "Epoch 887/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 189226224.0000 - val_loss: 2820986880.0000\n",
            "Epoch 888/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 184501952.0000 - val_loss: 2864529920.0000\n",
            "Epoch 889/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 194152576.0000 - val_loss: 2765834752.0000\n",
            "Epoch 890/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 188118640.0000 - val_loss: 2784430848.0000\n",
            "Epoch 891/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 186267232.0000 - val_loss: 2791642880.0000\n",
            "Epoch 892/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 184769120.0000 - val_loss: 2897641216.0000\n",
            "Epoch 893/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 184662768.0000 - val_loss: 2825188096.0000\n",
            "Epoch 894/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 181156080.0000 - val_loss: 2849053184.0000\n",
            "Epoch 895/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 183705840.0000 - val_loss: 2829934080.0000\n",
            "Epoch 896/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 180658896.0000 - val_loss: 2820092416.0000\n",
            "Epoch 897/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 179695328.0000 - val_loss: 2808362240.0000\n",
            "Epoch 898/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 179907632.0000 - val_loss: 2784879616.0000\n",
            "Epoch 899/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 185072992.0000 - val_loss: 2819044096.0000\n",
            "Epoch 900/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 184519392.0000 - val_loss: 2806332416.0000\n",
            "Epoch 901/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 178027264.0000 - val_loss: 2831538432.0000\n",
            "Epoch 902/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 179620336.0000 - val_loss: 2832625152.0000\n",
            "Epoch 903/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 177231792.0000 - val_loss: 2937687296.0000\n",
            "Epoch 904/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 178233248.0000 - val_loss: 2837039104.0000\n",
            "Epoch 905/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 177992912.0000 - val_loss: 2832455936.0000\n",
            "Epoch 906/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 177253440.0000 - val_loss: 2884944128.0000\n",
            "Epoch 907/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 175966928.0000 - val_loss: 2798590208.0000\n",
            "Epoch 908/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 178450464.0000 - val_loss: 2821550592.0000\n",
            "Epoch 909/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 177255792.0000 - val_loss: 2838690560.0000\n",
            "Epoch 910/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 175900816.0000 - val_loss: 2926413312.0000\n",
            "Epoch 911/1000\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 172770000.0000 - val_loss: 2789209856.0000\n",
            "Epoch 912/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 175215360.0000 - val_loss: 2907738624.0000\n",
            "Epoch 913/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 173844000.0000 - val_loss: 2773876736.0000\n",
            "Epoch 914/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 175502096.0000 - val_loss: 2818906624.0000\n",
            "Epoch 915/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 177297632.0000 - val_loss: 2854828288.0000\n",
            "Epoch 916/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 174716848.0000 - val_loss: 2882640640.0000\n",
            "Epoch 917/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 173252272.0000 - val_loss: 2934783232.0000\n",
            "Epoch 918/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 172510608.0000 - val_loss: 2803178496.0000\n",
            "Epoch 919/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 168781200.0000 - val_loss: 2894849536.0000\n",
            "Epoch 920/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 170608544.0000 - val_loss: 2899380480.0000\n",
            "Epoch 921/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 169518176.0000 - val_loss: 2940090368.0000\n",
            "Epoch 922/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 170364368.0000 - val_loss: 2907561472.0000\n",
            "Epoch 923/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 167645552.0000 - val_loss: 2889145600.0000\n",
            "Epoch 924/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 169642608.0000 - val_loss: 2893955584.0000\n",
            "Epoch 925/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 167985872.0000 - val_loss: 2886265600.0000\n",
            "Epoch 926/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 167828080.0000 - val_loss: 2796568832.0000\n",
            "Epoch 927/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 167024464.0000 - val_loss: 2868386816.0000\n",
            "Epoch 928/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 171885968.0000 - val_loss: 2802106624.0000\n",
            "Epoch 929/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 171516640.0000 - val_loss: 2949495552.0000\n",
            "Epoch 930/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 165549504.0000 - val_loss: 2935188736.0000\n",
            "Epoch 931/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 165352112.0000 - val_loss: 2971115008.0000\n",
            "Epoch 932/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 167498240.0000 - val_loss: 2850179840.0000\n",
            "Epoch 933/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 166540656.0000 - val_loss: 2877019904.0000\n",
            "Epoch 934/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 165816352.0000 - val_loss: 2846800896.0000\n",
            "Epoch 935/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 164003648.0000 - val_loss: 2900599296.0000\n",
            "Epoch 936/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 162088976.0000 - val_loss: 2909332224.0000\n",
            "Epoch 937/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 159556640.0000 - val_loss: 2908611584.0000\n",
            "Epoch 938/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 163432416.0000 - val_loss: 2860892672.0000\n",
            "Epoch 939/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 159637104.0000 - val_loss: 3003062528.0000\n",
            "Epoch 940/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 160941104.0000 - val_loss: 2933773312.0000\n",
            "Epoch 941/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 161333520.0000 - val_loss: 2914036224.0000\n",
            "Epoch 942/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 162504816.0000 - val_loss: 2970369024.0000\n",
            "Epoch 943/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 158117040.0000 - val_loss: 3014300416.0000\n",
            "Epoch 944/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 161316544.0000 - val_loss: 2922085120.0000\n",
            "Epoch 945/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 159066304.0000 - val_loss: 2951896320.0000\n",
            "Epoch 946/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 159872720.0000 - val_loss: 2986615552.0000\n",
            "Epoch 947/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 155474960.0000 - val_loss: 3037961728.0000\n",
            "Epoch 948/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 157967344.0000 - val_loss: 2991288320.0000\n",
            "Epoch 949/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 156333472.0000 - val_loss: 2978859264.0000\n",
            "Epoch 950/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 156302592.0000 - val_loss: 2965928960.0000\n",
            "Epoch 951/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 153752592.0000 - val_loss: 3051606016.0000\n",
            "Epoch 952/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 155522528.0000 - val_loss: 3171721216.0000\n",
            "Epoch 953/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 155415024.0000 - val_loss: 2971656192.0000\n",
            "Epoch 954/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 155061632.0000 - val_loss: 2925793024.0000\n",
            "Epoch 955/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 152237248.0000 - val_loss: 3061097984.0000\n",
            "Epoch 956/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 153647264.0000 - val_loss: 3039904768.0000\n",
            "Epoch 957/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 152584928.0000 - val_loss: 3160760576.0000\n",
            "Epoch 958/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 154348944.0000 - val_loss: 3022729984.0000\n",
            "Epoch 959/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 150373648.0000 - val_loss: 3006668800.0000\n",
            "Epoch 960/1000\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 148765984.0000 - val_loss: 2961187072.0000\n",
            "Epoch 961/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 151300272.0000 - val_loss: 3125554432.0000\n",
            "Epoch 962/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 150521376.0000 - val_loss: 3035252480.0000\n",
            "Epoch 963/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 152065216.0000 - val_loss: 3077912576.0000\n",
            "Epoch 964/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 148471248.0000 - val_loss: 3029800960.0000\n",
            "Epoch 965/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 146770672.0000 - val_loss: 3033997568.0000\n",
            "Epoch 966/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 146332304.0000 - val_loss: 2951536640.0000\n",
            "Epoch 967/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 148070608.0000 - val_loss: 3086650880.0000\n",
            "Epoch 968/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 149541040.0000 - val_loss: 3089865984.0000\n",
            "Epoch 969/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 148313472.0000 - val_loss: 3060894208.0000\n",
            "Epoch 970/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 145822448.0000 - val_loss: 2984020736.0000\n",
            "Epoch 971/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 154418608.0000 - val_loss: 3040638208.0000\n",
            "Epoch 972/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 144151232.0000 - val_loss: 2996732928.0000\n",
            "Epoch 973/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 145459056.0000 - val_loss: 2909868544.0000\n",
            "Epoch 974/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 147927792.0000 - val_loss: 3102139136.0000\n",
            "Epoch 975/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 141933920.0000 - val_loss: 3049948416.0000\n",
            "Epoch 976/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 140159456.0000 - val_loss: 3009747200.0000\n",
            "Epoch 977/1000\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 140601632.0000 - val_loss: 3150604800.0000\n",
            "Epoch 978/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 140749088.0000 - val_loss: 3014727936.0000\n",
            "Epoch 979/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 141900272.0000 - val_loss: 3017082112.0000\n",
            "Epoch 980/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 140410336.0000 - val_loss: 3117703936.0000\n",
            "Epoch 981/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 139414896.0000 - val_loss: 3218926336.0000\n",
            "Epoch 982/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 138637744.0000 - val_loss: 3036424192.0000\n",
            "Epoch 983/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 139648576.0000 - val_loss: 3121098240.0000\n",
            "Epoch 984/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 140019856.0000 - val_loss: 3094274048.0000\n",
            "Epoch 985/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 136674928.0000 - val_loss: 3078715392.0000\n",
            "Epoch 986/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 137256304.0000 - val_loss: 3028376832.0000\n",
            "Epoch 987/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 136858080.0000 - val_loss: 3015679744.0000\n",
            "Epoch 988/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 137195232.0000 - val_loss: 3165953792.0000\n",
            "Epoch 989/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 134653856.0000 - val_loss: 3053891072.0000\n",
            "Epoch 990/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 135067088.0000 - val_loss: 3163264256.0000\n",
            "Epoch 991/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 134324496.0000 - val_loss: 3123687680.0000\n",
            "Epoch 992/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 137169648.0000 - val_loss: 3046162688.0000\n",
            "Epoch 993/1000\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 136565088.0000 - val_loss: 3216759040.0000\n",
            "Epoch 994/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 136935888.0000 - val_loss: 3031874560.0000\n",
            "Epoch 995/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 132545312.0000 - val_loss: 3170820096.0000\n",
            "Epoch 996/1000\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 131503960.0000 - val_loss: 3069528320.0000\n",
            "Epoch 997/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 135902976.0000 - val_loss: 3201672704.0000\n",
            "Epoch 998/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 132294320.0000 - val_loss: 3179496448.0000\n",
            "Epoch 999/1000\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 131517032.0000 - val_loss: 3070943232.0000\n",
            "Epoch 1000/1000\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 132923408.0000 - val_loss: 3133737216.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "39YzoUPSlnV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred = model.predict(x_train_scaled)\n",
        "\n",
        "y_val_pred = y_val_pred.flatten()\n",
        "\n",
        "\n",
        "r2_val = r2_score(y_train, y_val_pred)\n",
        "print(\"R2 Score:\", r2_val)\n",
        "print(\"Prediction on data validation:\")\n",
        "print(y_val_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqTvXAsR_pIE",
        "outputId": "34c0285e-27e8-49de-84a6-3360f213db71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 3ms/step\n",
            "R2 Score: 0.884580625339368\n",
            "Prediction on data validation:\n",
            "[210694.34 199376.61 197933.48 145318.83 278203.75 142572.58 302653.8\n",
            " 198709.36 131723.92 117680.29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "r2_scores_cv = []\n",
        "\n",
        "for train_index, val_index in kf.split(x_train_scaled):\n",
        "    x_train_cv, x_val_cv = x_train_scaled[train_index], x_train_scaled[val_index]\n",
        "    y_train_cv, y_val_cv = y_train[train_index], y_train[val_index]\n",
        "\n",
        "    model = create_model(input_dim=x_train_scaled.shape[1])\n",
        "\n",
        "    model.fit(x_train_cv, y_train_cv, epochs=50, batch_size=32, validation_data=(x_val_cv, y_val_cv) )\n",
        "\n",
        "    y_pred_val_cv = model.predict(x_val_cv).flatten()\n",
        "\n",
        "    r2_val_cv = r2_score(y_val_cv, y_pred_val_cv)\n",
        "    r2_scores_cv.append(r2_val_cv)\n",
        "\n",
        "print(\"R2 Scores:\", r2_scores_cv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uouXqFhPASec",
        "outputId": "d6f501a0-60ed-408d-fac3-b68f5f51e6be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "37/37 [==============================] - 2s 13ms/step - loss: 38883598336.0000 - val_loss: 39646687232.0000\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 38849265664.0000 - val_loss: 39555547136.0000\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 38592028672.0000 - val_loss: 39021043712.0000\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 37552230400.0000 - val_loss: 37190049792.0000\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 34632122368.0000 - val_loss: 32692355072.0000\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 28652773376.0000 - val_loss: 24951234560.0000\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 20142092288.0000 - val_loss: 15665549312.0000\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 12705800192.0000 - val_loss: 9233199104.0000\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 8964170752.0000 - val_loss: 6906996224.0000\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 7699903488.0000 - val_loss: 5841771008.0000\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 6792116224.0000 - val_loss: 5172106752.0000\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 6129696256.0000 - val_loss: 4628153856.0000\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 5580623360.0000 - val_loss: 4350600704.0000\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 5146908160.0000 - val_loss: 4041662464.0000\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 4771830784.0000 - val_loss: 3766775296.0000\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 4432070144.0000 - val_loss: 3525216000.0000\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 4141688832.0000 - val_loss: 3311157248.0000\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 3842817280.0000 - val_loss: 3094624256.0000\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 3587196160.0000 - val_loss: 2906151424.0000\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 3354510592.0000 - val_loss: 2746791936.0000\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 3134068224.0000 - val_loss: 2574827520.0000\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2941014528.0000 - val_loss: 2452962048.0000\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2759924992.0000 - val_loss: 2310912256.0000\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2602679296.0000 - val_loss: 2181528832.0000\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2473176576.0000 - val_loss: 2119959040.0000\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2340215552.0000 - val_loss: 2024222336.0000\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2222206208.0000 - val_loss: 1958996096.0000\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2110667392.0000 - val_loss: 1895079168.0000\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2018596352.0000 - val_loss: 1840110720.0000\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1935564032.0000 - val_loss: 1784260096.0000\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1863316864.0000 - val_loss: 1728235008.0000\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1793242368.0000 - val_loss: 1727248768.0000\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1727517056.0000 - val_loss: 1682278144.0000\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1689202560.0000 - val_loss: 1651993856.0000\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1622304000.0000 - val_loss: 1623566592.0000\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1592630400.0000 - val_loss: 1592815488.0000\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1539003904.0000 - val_loss: 1558530304.0000\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1503070848.0000 - val_loss: 1564728448.0000\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1472594176.0000 - val_loss: 1541876992.0000\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1431834112.0000 - val_loss: 1543348608.0000\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1406739968.0000 - val_loss: 1521078656.0000\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1381116800.0000 - val_loss: 1507087488.0000\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1355890560.0000 - val_loss: 1487980800.0000\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1329762304.0000 - val_loss: 1481082496.0000\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1310771072.0000 - val_loss: 1481956096.0000\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1287478784.0000 - val_loss: 1450597888.0000\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1279562752.0000 - val_loss: 1424129664.0000\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1271998464.0000 - val_loss: 1431129728.0000\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1248316032.0000 - val_loss: 1400004096.0000\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1231366016.0000 - val_loss: 1463862528.0000\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 1s 11ms/step - loss: 38447611904.0000 - val_loss: 41385533440.0000\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 38407311360.0000 - val_loss: 41269653504.0000\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 38105001984.0000 - val_loss: 40583909376.0000\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 36811218944.0000 - val_loss: 38178828288.0000\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 33420820480.0000 - val_loss: 32683317248.0000\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 26866376704.0000 - val_loss: 23379202048.0000\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 17662320640.0000 - val_loss: 13012496384.0000\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 10376705024.0000 - val_loss: 7046684672.0000\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 7367288320.0000 - val_loss: 5341464064.0000\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 6321924096.0000 - val_loss: 4658501120.0000\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 5703305728.0000 - val_loss: 4233041152.0000\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 5247525888.0000 - val_loss: 3925558272.0000\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 4805163520.0000 - val_loss: 3618873088.0000\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 4428921344.0000 - val_loss: 3373467392.0000\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 4094625024.0000 - val_loss: 3122301952.0000\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 3776810496.0000 - val_loss: 2867644672.0000\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3503689984.0000 - val_loss: 2652708352.0000\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 3312240640.0000 - val_loss: 2535233792.0000\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3058365440.0000 - val_loss: 2379251456.0000\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2848846848.0000 - val_loss: 2239226880.0000\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2674890752.0000 - val_loss: 2157455872.0000\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2531064576.0000 - val_loss: 2031720192.0000\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 2384259584.0000 - val_loss: 1929278848.0000\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2269971456.0000 - val_loss: 1898289536.0000\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2158229504.0000 - val_loss: 1827515776.0000\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2064057216.0000 - val_loss: 1764732416.0000\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1985486464.0000 - val_loss: 1716446592.0000\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1902265472.0000 - val_loss: 1661713920.0000\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1846907776.0000 - val_loss: 1644655488.0000\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1776257280.0000 - val_loss: 1610544896.0000\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1721205888.0000 - val_loss: 1567255552.0000\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1679811072.0000 - val_loss: 1556310272.0000\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1632746240.0000 - val_loss: 1507860096.0000\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1586076672.0000 - val_loss: 1514565504.0000\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1552925312.0000 - val_loss: 1509706368.0000\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1514004992.0000 - val_loss: 1486984192.0000\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1482299520.0000 - val_loss: 1457232896.0000\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1447280128.0000 - val_loss: 1458747136.0000\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1425372032.0000 - val_loss: 1446191616.0000\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1390850944.0000 - val_loss: 1436914560.0000\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1370015744.0000 - val_loss: 1413350272.0000\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1342419968.0000 - val_loss: 1431829760.0000\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1321411712.0000 - val_loss: 1392279168.0000\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1296700544.0000 - val_loss: 1422693504.0000\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1272535808.0000 - val_loss: 1403045248.0000\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1254901632.0000 - val_loss: 1394872320.0000\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1234064128.0000 - val_loss: 1393882752.0000\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1214453248.0000 - val_loss: 1379423488.0000\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1198786816.0000 - val_loss: 1381073664.0000\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1179187840.0000 - val_loss: 1374666752.0000\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 1s 7ms/step - loss: 39297163264.0000 - val_loss: 37980315648.0000\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 39248490496.0000 - val_loss: 37854142464.0000\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 38930608128.0000 - val_loss: 37168332800.0000\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 37562134528.0000 - val_loss: 34815438848.0000\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 33802223616.0000 - val_loss: 29436383232.0000\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 26463221760.0000 - val_loss: 21291589632.0000\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 17110765568.0000 - val_loss: 15394036736.0000\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 10727372800.0000 - val_loss: 15105295360.0000\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 8628684800.0000 - val_loss: 14998037504.0000\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 7525827584.0000 - val_loss: 13765469184.0000\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 6461220352.0000 - val_loss: 12529705984.0000\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 5475213312.0000 - val_loss: 11513434112.0000\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 4616424448.0000 - val_loss: 10503953408.0000\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 3908676096.0000 - val_loss: 9603286016.0000\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 3356048128.0000 - val_loss: 8898220032.0000\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 2932114944.0000 - val_loss: 8256952320.0000\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2609209600.0000 - val_loss: 7671447552.0000\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2351564032.0000 - val_loss: 7238314496.0000\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2136055680.0000 - val_loss: 6914880000.0000\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1958316672.0000 - val_loss: 6604488192.0000\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1803377792.0000 - val_loss: 6273574912.0000\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1672615936.0000 - val_loss: 6031910912.0000\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1560014464.0000 - val_loss: 5816585216.0000\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1462071040.0000 - val_loss: 5676832256.0000\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1379409280.0000 - val_loss: 5544348160.0000\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1304550656.0000 - val_loss: 5364038144.0000\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1242400000.0000 - val_loss: 5338925568.0000\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1184675328.0000 - val_loss: 5230498304.0000\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1137362048.0000 - val_loss: 5116590080.0000\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1091866496.0000 - val_loss: 5143408640.0000\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1053160704.0000 - val_loss: 5044263936.0000\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1020397184.0000 - val_loss: 5048481792.0000\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 988068416.0000 - val_loss: 4985285120.0000\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 961430720.0000 - val_loss: 4960709120.0000\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 931132608.0000 - val_loss: 4889435648.0000\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 907267712.0000 - val_loss: 4872069120.0000\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 889875840.0000 - val_loss: 4781540352.0000\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 867603456.0000 - val_loss: 4819460608.0000\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 848883328.0000 - val_loss: 4811354112.0000\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 830039616.0000 - val_loss: 4717758464.0000\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 815047488.0000 - val_loss: 4741770240.0000\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 795887168.0000 - val_loss: 4619788288.0000\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 785213120.0000 - val_loss: 4725295104.0000\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 772131392.0000 - val_loss: 4722664448.0000\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 755585024.0000 - val_loss: 4734890496.0000\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 743455168.0000 - val_loss: 4656822272.0000\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 733283456.0000 - val_loss: 4626944000.0000\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 722757952.0000 - val_loss: 4653451264.0000\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 715664896.0000 - val_loss: 4676518912.0000\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 699502592.0000 - val_loss: 4691766784.0000\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 1s 8ms/step - loss: 39189336064.0000 - val_loss: 38415716352.0000\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 39140663296.0000 - val_loss: 38295400448.0000\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 38806593536.0000 - val_loss: 37619073024.0000\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 37390913536.0000 - val_loss: 35309015040.0000\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 33577852928.0000 - val_loss: 29903017984.0000\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 26076139520.0000 - val_loss: 21103419392.0000\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 16435396608.0000 - val_loss: 12023379968.0000\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 9738588160.0000 - val_loss: 7663627264.0000\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 7503917568.0000 - val_loss: 6270523392.0000\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 6545745920.0000 - val_loss: 5582024192.0000\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 5856094720.0000 - val_loss: 5068272640.0000\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 5339858432.0000 - val_loss: 4715433472.0000\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 4918446080.0000 - val_loss: 4409899008.0000\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 4589922304.0000 - val_loss: 4083878144.0000\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 4248249600.0000 - val_loss: 3815703040.0000\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 3897092352.0000 - val_loss: 3492808704.0000\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 3632346624.0000 - val_loss: 3235031040.0000\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 3406188544.0000 - val_loss: 3037720576.0000\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 3153458432.0000 - val_loss: 2776415232.0000\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2957562368.0000 - val_loss: 2640407296.0000\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2766920192.0000 - val_loss: 2445859072.0000\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2597269760.0000 - val_loss: 2291568384.0000\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2436547328.0000 - val_loss: 2145335040.0000\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2323523328.0000 - val_loss: 2043457792.0000\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2227722240.0000 - val_loss: 1940543360.0000\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2104883456.0000 - val_loss: 1855548032.0000\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2009804160.0000 - val_loss: 1786238464.0000\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1932466560.0000 - val_loss: 1716702080.0000\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1867575296.0000 - val_loss: 1648563968.0000\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1812182272.0000 - val_loss: 1596713344.0000\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1769036672.0000 - val_loss: 1544713984.0000\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1689716992.0000 - val_loss: 1516444928.0000\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1651302144.0000 - val_loss: 1466501504.0000\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1603508224.0000 - val_loss: 1433417472.0000\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1581647232.0000 - val_loss: 1408815872.0000\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1533694720.0000 - val_loss: 1377640320.0000\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1498264576.0000 - val_loss: 1359604864.0000\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1473199616.0000 - val_loss: 1326848640.0000\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1438846592.0000 - val_loss: 1307406720.0000\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1411383424.0000 - val_loss: 1288296576.0000\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1391242624.0000 - val_loss: 1269162880.0000\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1373735424.0000 - val_loss: 1257617536.0000\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1341641472.0000 - val_loss: 1234752384.0000\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1318138368.0000 - val_loss: 1219149824.0000\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1312342784.0000 - val_loss: 1211365760.0000\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1283088000.0000 - val_loss: 1194519168.0000\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1262133632.0000 - val_loss: 1182309632.0000\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1244607360.0000 - val_loss: 1174318208.0000\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1223203072.0000 - val_loss: 1159346816.0000\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1215000576.0000 - val_loss: 1144752256.0000\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "37/37 [==============================] - 1s 8ms/step - loss: 39365165056.0000 - val_loss: 37719494656.0000\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 39330095104.0000 - val_loss: 37636612096.0000\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 39090274304.0000 - val_loss: 37171752960.0000\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 38027890688.0000 - val_loss: 35546275840.0000\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 35097538560.0000 - val_loss: 31497541632.0000\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 28911894528.0000 - val_loss: 24397539328.0000\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 20174727168.0000 - val_loss: 15734534144.0000\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 12735308800.0000 - val_loss: 10062649344.0000\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 9246343168.0000 - val_loss: 7959353344.0000\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 7942407680.0000 - val_loss: 6876799488.0000\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 7043577856.0000 - val_loss: 6045274624.0000\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 6369866752.0000 - val_loss: 5413173248.0000\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 5821559808.0000 - val_loss: 4928600064.0000\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 5376273920.0000 - val_loss: 4564662784.0000\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 5009950720.0000 - val_loss: 4207616768.0000\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 4694245888.0000 - val_loss: 3898481152.0000\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 4408882176.0000 - val_loss: 3701953536.0000\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 4123679488.0000 - val_loss: 3420810496.0000\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3898606592.0000 - val_loss: 3190658304.0000\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 3683051776.0000 - val_loss: 3000258304.0000\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 3463128832.0000 - val_loss: 2801440768.0000\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 3270616832.0000 - val_loss: 2635301888.0000\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 3100146432.0000 - val_loss: 2482808576.0000\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2939512064.0000 - val_loss: 2348169216.0000\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 2792160256.0000 - val_loss: 2189339904.0000\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 2688006912.0000 - val_loss: 2090119168.0000\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 2544591872.0000 - val_loss: 1965409152.0000\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2429368576.0000 - val_loss: 1876760448.0000\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 2344586240.0000 - val_loss: 1767089152.0000\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 2248452608.0000 - val_loss: 1729435648.0000\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2159342336.0000 - val_loss: 1634455424.0000\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 2095095936.0000 - val_loss: 1575952000.0000\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 2017911168.0000 - val_loss: 1518860032.0000\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1961264000.0000 - val_loss: 1461554432.0000\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 1899856512.0000 - val_loss: 1401517184.0000\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 0s 10ms/step - loss: 1850125568.0000 - val_loss: 1358903936.0000\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 0s 8ms/step - loss: 1814747264.0000 - val_loss: 1308585856.0000\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 0s 13ms/step - loss: 1775931136.0000 - val_loss: 1289068672.0000\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 1s 15ms/step - loss: 1730943616.0000 - val_loss: 1236650752.0000\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 0s 12ms/step - loss: 1687303424.0000 - val_loss: 1231187328.0000\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1659849984.0000 - val_loss: 1198666752.0000\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 0s 9ms/step - loss: 1640342016.0000 - val_loss: 1169425024.0000\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 0s 11ms/step - loss: 1592774144.0000 - val_loss: 1147230464.0000\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1560613760.0000 - val_loss: 1123013376.0000\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1547953024.0000 - val_loss: 1098371456.0000\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1512619520.0000 - val_loss: 1092199552.0000\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1493386496.0000 - val_loss: 1061320512.0000\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1474348032.0000 - val_loss: 1049641728.0000\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1448323072.0000 - val_loss: 1040112192.0000\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1427218560.0000 - val_loss: 1025665664.0000\n",
            "10/10 [==============================] - 0s 7ms/step\n",
            "R2 Scores: [0.8091525018439581, 0.7978213654077557, 0.15075931119253794, 0.8176885984053527, 0.8037703542024343]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(input_dim=x_train_scaled.shape[1])\n",
        "\n",
        "model.fit(x_train_scaled, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "y_train_pred = model.predict(x_train_scaled).flatten()\n",
        "\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "print(\"R2 Score:\", r2_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zeYRlyMrBo31",
        "outputId": "1110bfe1-8af2-4dfb-bc3f-ef663b8c7c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "37/37 [==============================] - 1s 8ms/step - loss: 38817480704.0000 - val_loss: 39911780352.0000\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 38787510272.0000 - val_loss: 39833075712.0000\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 38540394496.0000 - val_loss: 39383982080.0000\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 37526597632.0000 - val_loss: 37818871808.0000\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 34757799936.0000 - val_loss: 34088247296.0000\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 29044975616.0000 - val_loss: 27642687488.0000\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 20408092672.0000 - val_loss: 19800061952.0000\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 12164556800.0000 - val_loss: 14616207360.0000\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 8112817152.0000 - val_loss: 12932976640.0000\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 6753411072.0000 - val_loss: 11943371776.0000\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 5951346176.0000 - val_loss: 11113814016.0000\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 5333736960.0000 - val_loss: 10415434752.0000\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 4858641920.0000 - val_loss: 9793731584.0000\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 4491679232.0000 - val_loss: 9265568768.0000\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 4168350464.0000 - val_loss: 8820072448.0000\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 3870413824.0000 - val_loss: 8372794880.0000\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 3612387840.0000 - val_loss: 7975867904.0000\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 3381778944.0000 - val_loss: 7551272448.0000\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 3168271104.0000 - val_loss: 7216154624.0000\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2961764352.0000 - val_loss: 6835731968.0000\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2790503168.0000 - val_loss: 6491748864.0000\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2599134976.0000 - val_loss: 6147134464.0000\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2447730176.0000 - val_loss: 5891341824.0000\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2308595712.0000 - val_loss: 5575819264.0000\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 2180425728.0000 - val_loss: 5299506688.0000\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 2049926528.0000 - val_loss: 5059906560.0000\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1941736320.0000 - val_loss: 4782571520.0000\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1844585856.0000 - val_loss: 4582042112.0000\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1804107264.0000 - val_loss: 4378223104.0000\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1679209344.0000 - val_loss: 4165850112.0000\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1606237056.0000 - val_loss: 4020019968.0000\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1543597056.0000 - val_loss: 3865993216.0000\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1486348672.0000 - val_loss: 3749175040.0000\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1434576896.0000 - val_loss: 3619201792.0000\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1391232512.0000 - val_loss: 3504705280.0000\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 1352598528.0000 - val_loss: 3382616064.0000\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1318154880.0000 - val_loss: 3302273792.0000\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1278812544.0000 - val_loss: 3218834176.0000\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1245752576.0000 - val_loss: 3148069888.0000\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1223839744.0000 - val_loss: 3071905792.0000\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1192989824.0000 - val_loss: 2994671104.0000\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1165909504.0000 - val_loss: 2950308864.0000\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1145158784.0000 - val_loss: 2899556864.0000\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1122960128.0000 - val_loss: 2852199424.0000\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1105437568.0000 - val_loss: 2815105280.0000\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1090451712.0000 - val_loss: 2766125568.0000\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1075635328.0000 - val_loss: 2729024256.0000\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1052336576.0000 - val_loss: 2697264128.0000\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 1039671744.0000 - val_loss: 2669742336.0000\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 1026072832.0000 - val_loss: 2638673920.0000\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 1010376832.0000 - val_loss: 2609418752.0000\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 1001529344.0000 - val_loss: 2584221440.0000\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 985000128.0000 - val_loss: 2564401408.0000\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 981016704.0000 - val_loss: 2534285312.0000\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 964043648.0000 - val_loss: 2510530560.0000\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 949490176.0000 - val_loss: 2491449856.0000\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 942627264.0000 - val_loss: 2466340864.0000\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 929261824.0000 - val_loss: 2449611776.0000\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 927664064.0000 - val_loss: 2434460672.0000\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 916072064.0000 - val_loss: 2406846976.0000\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 903146112.0000 - val_loss: 2395545856.0000\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 897176256.0000 - val_loss: 2380567040.0000\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 888911360.0000 - val_loss: 2369748736.0000\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 881064960.0000 - val_loss: 2348047360.0000\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 873634240.0000 - val_loss: 2340091392.0000\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 869063872.0000 - val_loss: 2325307904.0000\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 862607360.0000 - val_loss: 2309962240.0000\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 849829376.0000 - val_loss: 2295775488.0000\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 844542144.0000 - val_loss: 2287173120.0000\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 835594624.0000 - val_loss: 2266488576.0000\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 827293632.0000 - val_loss: 2261691136.0000\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 830523712.0000 - val_loss: 2263372544.0000\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 819709184.0000 - val_loss: 2241345536.0000\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 812125440.0000 - val_loss: 2235459584.0000\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 814333312.0000 - val_loss: 2234966016.0000\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 809697600.0000 - val_loss: 2218462720.0000\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 810458944.0000 - val_loss: 2200671488.0000\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 801522240.0000 - val_loss: 2193975296.0000\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 0s 3ms/step - loss: 792788736.0000 - val_loss: 2193144320.0000\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 787550784.0000 - val_loss: 2186361856.0000\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 783890496.0000 - val_loss: 2171099648.0000\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 775938304.0000 - val_loss: 2175281920.0000\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 773097152.0000 - val_loss: 2160016896.0000\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 772263040.0000 - val_loss: 2149146880.0000\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 765168960.0000 - val_loss: 2149392640.0000\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 758600704.0000 - val_loss: 2141253888.0000\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 758647616.0000 - val_loss: 2146415744.0000\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 751737408.0000 - val_loss: 2131035648.0000\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 753282304.0000 - val_loss: 2130098176.0000\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 753369152.0000 - val_loss: 2109539840.0000\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 0s 7ms/step - loss: 743998720.0000 - val_loss: 2115521408.0000\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 742532480.0000 - val_loss: 2100773760.0000\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 743354304.0000 - val_loss: 2117945984.0000\n",
            "Epoch 94/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 742874496.0000 - val_loss: 2094891904.0000\n",
            "Epoch 95/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 733505408.0000 - val_loss: 2098894976.0000\n",
            "Epoch 96/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 725066688.0000 - val_loss: 2089444608.0000\n",
            "Epoch 97/100\n",
            "37/37 [==============================] - 0s 5ms/step - loss: 724949568.0000 - val_loss: 2084901504.0000\n",
            "Epoch 98/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 722434240.0000 - val_loss: 2087312384.0000\n",
            "Epoch 99/100\n",
            "37/37 [==============================] - 0s 6ms/step - loss: 718299776.0000 - val_loss: 2091655936.0000\n",
            "Epoch 100/100\n",
            "37/37 [==============================] - 0s 4ms/step - loss: 717913536.0000 - val_loss: 2081971712.0000\n",
            "46/46 [==============================] - 0s 1ms/step\n",
            "R2 Score: 0.8445544439730238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test_scaled)\n",
        "\n",
        "y_pred = y_pred.flatten()\n",
        "\n",
        "print(\"Prediction on data test:\")\n",
        "print(y_pred[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bREOth1akHUH",
        "outputId": "443ead07-6eb9-46db-ca77-99a5bd43a241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46/46 [==============================] - 0s 2ms/step\n",
            "Prediction on data test:\n",
            "[110566.43 161088.95 179330.58 201613.92 185824.28 182598.58 193031.73\n",
            " 176082.61 188880.69 127238.01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_score = r2_score(y_val_cv, y_pred_val_cv)\n",
        "print(\"Test Score:\", cv_score)\n",
        "\n",
        "train_score = r2_score(y_train, model.predict(x_train_scaled))\n",
        "print(\"Train Score:\", train_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbDdJ_TPlqeA",
        "outputId": "d57bfe81-097a-44d5-9fbb-a75a7b454f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Score: 0.8037703542024343\n",
            "46/46 [==============================] - 0s 2ms/step\n",
            "Train Score: 0.8445544439730238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({'Id': df_test['Id'], 'SalePrice': y_pred})\n",
        "\n",
        "submission.to_csv('predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "aFDoJ0lUmjlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_prediction = pd.read_csv('predictions.csv')\n",
        "\n",
        "df_prediction.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_108_zh_wM8J",
        "outputId": "a1647ba5-5bef-469b-f5ef-d4ee17d239e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Id  SalePrice\n",
              "0  1461  110566.43\n",
              "1  1462  161088.95\n",
              "2  1463  179330.58\n",
              "3  1464  201613.92\n",
              "4  1465  185824.28"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a270fc8-3081-4df9-85c0-5d93a675f394\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1461</td>\n",
              "      <td>110566.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1462</td>\n",
              "      <td>161088.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1463</td>\n",
              "      <td>179330.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1464</td>\n",
              "      <td>201613.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1465</td>\n",
              "      <td>185824.28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a270fc8-3081-4df9-85c0-5d93a675f394')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a270fc8-3081-4df9-85c0-5d93a675f394 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a270fc8-3081-4df9-85c0-5d93a675f394');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86c47186-aadf-4aa6-8a76-4203f59c5a40\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86c47186-aadf-4aa6-8a76-4203f59c5a40')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86c47186-aadf-4aa6-8a76-4203f59c5a40 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_prediction",
              "summary": "{\n  \"name\": \"df_prediction\",\n  \"rows\": 1459,\n  \"fields\": [\n    {\n      \"column\": \"Id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 421,\n        \"min\": 1461,\n        \"max\": 2919,\n        \"num_unique_values\": 1459,\n        \"samples\": [\n          2782,\n          2297,\n          1874\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SalePrice\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80678.29574382101,\n        \"min\": 53193.816,\n        \"max\": 719004.06,\n        \"num_unique_values\": 1459,\n        \"samples\": [\n          92186.36,\n          310659.44,\n          140253.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}